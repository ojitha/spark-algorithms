{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2159f75-6c2a-4fcf-85c0-2fefc3247059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.logging.log4j.{LogManager, Level}\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.logging.log4j.core.config.Configurator\u001b[39m"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Enable compiler to use Java classpath (REMOVED the invalid doc.value line)\n",
    "interp.configureCompiler(c => {\n",
    "c.settings.usejavacp.value = true\n",
    "})\n",
    "\n",
    "// Configure Coursier to fetch doc JARs\n",
    "// Import Spark\n",
    "import $ivy.`org.apache.spark::spark-sql:3.5.7`\n",
    "// import Almond Spark plugin\n",
    "// import $ivy.`sh.almond::almond-spark:0.14.0-RC8`\n",
    "\n",
    "import org.apache.logging.log4j.{LogManager, Level}\n",
    "import org.apache.logging.log4j.core.config.Configurator\n",
    "// Set log levels BEFORE creating SparkSession\n",
    "Configurator.setRootLevel(Level.WARN)\n",
    "Configurator.setLevel(\"org.apache.spark\", Level.WARN)\n",
    "Configurator.setLevel(\"org.apache.spark.executor.Executor\", Level.WARN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9d08b8e-b811-4d39-af24-2beee2c5f4c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Loading <code>spark-stubs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Getting spark JARs\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Creating SparkSession\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07:25:26.671 [scala-kernel-interpreter-1] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a target=\"_blank\" href=\"http://localhost:4040\">Spark UI</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Spark 3.5.7 ready\n",
      "üåê Spark UI: http://localhost:4040\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql._\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.log4j.{Level, Logger}\u001b[39m\n",
       "\u001b[36mspark\u001b[39m: \u001b[32mSparkSession\u001b[39m = org.apache.spark.sql.SparkSession@7c8da0db\n",
       "\u001b[36mres2_5\u001b[39m: \u001b[32mSparkSession\u001b[39m = org.apache.spark.sql.SparkSession@7c8da0db\n",
       "\u001b[32mimport \u001b[39m\u001b[36mspark.implicits._\u001b[39m"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql._\n",
    "import org.apache.log4j.{Level, Logger}\n",
    "\n",
    "// Silence logs\n",
    "Logger.getLogger(\"org\").setLevel(Level.ERROR)\n",
    "Logger.getLogger(\"akka\").setLevel(Level.ERROR)\n",
    "\n",
    "val spark = {\n",
    "  NotebookSparkSession.builder()\n",
    "    .appName(\"2025-11-07-SparkDataset\")\n",
    "    .master(\"local[*]\")\n",
    "    .config(\"spark.driver.host\", \"localhost\")\n",
    "    .config(\"spark.driver.bindAddress\", \"0.0.0.0\")\n",
    "    .config(\"spark.driver.memory\", \"6g\")\n",
    "    .config(\"spark.ui.showConsoleProgress\", \"false\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", \"true\")\n",
    "    .getOrCreate()\n",
    "}\n",
    "\n",
    "// ‚≠ê CRITICAL: This line forces the UI widget to persist after the cell is done\n",
    "spark\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "import spark.implicits._\n",
    "\n",
    "println(s\"‚úÖ Spark ${spark.version} ready\")\n",
    "println(s\"üåê Spark UI: http://localhost:4040\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cf43c49-97b0-47bb-8447-2c6072a31519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mclass\u001b[39m \u001b[36mEntityNode\u001b[39m"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// create a case class for the `nodes-entities.csv`\n",
    "/**\n",
    "  * Represents an entity from the nodes-entities.csv file.\n",
    "  *\n",
    "  * @param node_id The unique identifier for the node.\n",
    "  * @param name The name of the entity.\n",
    "  * @param original_name The original name of the entity, if different.\n",
    "  * @param former_name A previous name for the entity.\n",
    "  * @param jurisdiction The legal jurisdiction of the entity.\n",
    "  * @param jurisdiction_description A description of the jurisdiction.\n",
    "  * @param company_type The type of company (e.g., Limited, Corp).\n",
    "  * @param address The registered address of the entity.\n",
    "  * @param incorporation_date The date the entity was incorporated.\n",
    "  * @param inactivation_date The date the entity was inactivated.\n",
    "  * @param struck_off_date The date the entity was struck off the register.\n",
    "  * @param status The current status of the entity.\n",
    "  * @param service_provider The service provider associated with the entity.\n",
    "  * @param ibc_ruc The IBC or RUC number.\n",
    "  * @param country_codes The country codes associated with the entity.\n",
    "  * @param countries The countries associated with the entity.\n",
    "  * @param sourceID The ID of the data source.\n",
    "  * @param valid_until The date until which the data is considered valid.\n",
    "  * @param note Any additional notes.\n",
    "  */\n",
    "case class EntityNode(\n",
    "    node_id: String,\n",
    "    name: Option[String],\n",
    "    original_name: Option[String],\n",
    "    former_name: Option[String],\n",
    "    jurisdiction: Option[String],\n",
    "    jurisdiction_description: Option[String],\n",
    "    company_type: Option[String],\n",
    "    address: Option[String],\n",
    "    incorporation_date: Option[String],\n",
    "    inactivation_date: Option[String],\n",
    "    struck_off_date: Option[String],\n",
    "    status: Option[String],\n",
    "    service_provider: Option[String],\n",
    "    ibcRuc: Option[String],\n",
    "    country_codes: Option[String],\n",
    "    countries: Option[String],\n",
    "    sourceID: Option[String],\n",
    "    valid_until: Option[String],\n",
    "    note: Option[String]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f78d8e1-097b-4512-946c-05cadab84b6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+-----------+------------+------------------------+------------+--------------------+-----------+------------------+-----------------+---------------+---------+---------+----------------+------+-------------+---------+-------------+--------------------+----+\n",
      "| node_id|                name|       original_name|former_name|jurisdiction|jurisdiction_description|company_type|             address|internal_id|incorporation_date|inactivation_date|struck_off_date|dorm_date|   status|service_provider|ibcRUC|country_codes|countries|     sourceID|         valid_until|note|\n",
      "+--------+--------------------+--------------------+-----------+------------+------------------------+------------+--------------------+-----------+------------------+-----------------+---------------+---------+---------+----------------+------+-------------+---------+-------------+--------------------+----+\n",
      "|10000001|TIANSHENG INDUSTR...|TIANSHENG INDUSTR...|       NULL|         SAM|                   Samoa|        NULL|ORION HOUSE SERVI...|    1001256|       23-MAR-2006|      18-FEB-2013|    15-FEB-2013|     NULL|Defaulted| Mossack Fonseca| 25221|          HKG|Hong Kong|Panama Papers|The Panama Papers...|NULL|\n",
      "|10000002|NINGBO SUNRISE EN...|NINGBO SUNRISE EN...|       NULL|         SAM|                   Samoa|        NULL|ORION HOUSE SERVI...|    1001263|       27-MAR-2006|      27-FEB-2014|    15-FEB-2014|     NULL|Defaulted| Mossack Fonseca| 25249|          HKG|Hong Kong|Panama Papers|The Panama Papers...|NULL|\n",
      "|10000003|  HOTFOCUS CO., LTD.|  HOTFOCUS CO., LTD.|       NULL|         SAM|                   Samoa|        NULL|ORION HOUSE SERVI...|    1000896|       10-JAN-2006|      15-FEB-2012|    15-FEB-2012|     NULL|Defaulted| Mossack Fonseca| 24138|          HKG|Hong Kong|Panama Papers|The Panama Papers...|NULL|\n",
      "|10000004|SKY-BLUE GIFTS & ...|SKY-BLUE GIFTS & ...|       NULL|         SAM|                   Samoa|        NULL|ORION HOUSE SERVI...|    1000914|       06-JAN-2006|      16-FEB-2009|    15-FEB-2009|     NULL|Defaulted| Mossack Fonseca| 24012|          HKG|Hong Kong|Panama Papers|The Panama Papers...|NULL|\n",
      "+--------+--------------------+--------------------+-----------+------------+------------------------+------------+--------------------+-----------+------------------+-----------------+---------------+---------+---------+----------------+------+-------------+---------+-------------+--------------------+----+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mentityNodeDS\u001b[39m: \u001b[32mDataset\u001b[39m[\u001b[32mEntityNode\u001b[39m] = [node_id: string, name: string ... 19 more fields]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Read CSV and convert to Dataset\n",
    "val entityNodeDS = spark.read\n",
    "  .option(\"header\", \"true\")\n",
    "  .option(\"inferSchema\", \"true\")\n",
    "  .csv(\"full-oldb.LATEST/nodes-entities.csv\")\n",
    "  .as[EntityNode]\n",
    "\n",
    "// Example queries\n",
    "entityNodeDS.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70ef2b2a-c05a-4b8d-84d6-d1c358c8f044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mclass\u001b[39m \u001b[36mIntermediary\u001b[39m"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// create a case class for the `nodes-intermediaries.csv`\n",
    "/**\n",
    "  * Represents an intermediary from the nodes-intermediaries.csv file.\n",
    "  *\n",
    "  * @param node_id The unique identifier for the node.\n",
    "  * @param name The name of the intermediary.\n",
    "  * @param status The current status of the intermediary.\n",
    "  * @param internal_id An internal identifier used by the source.\n",
    "  * @param address The address of the intermediary.\n",
    "  * @param countries The countries associated with the intermediary.\n",
    "  * @param country_codes The country codes associated with the intermediary.\n",
    "  * @param sourceID The ID of the data source.\n",
    "  * @param valid_until The date until which the data is considered valid.\n",
    "  * @param note Any additional notes.\n",
    "  */\n",
    "case class Intermediary(\n",
    "    node_id: String,\n",
    "    name: String,\n",
    "    status: Option[String],\n",
    "    internal_id: Option[String],\n",
    "    address: Option[String],\n",
    "    countries: Option[String],\n",
    "    country_codes: Option[String],\n",
    "    sourceID: String,\n",
    "    valid_until: String,\n",
    "    note: Option[String]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a0d581b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------------+---------+-----------+-----------------------------------------------------------------------------------------------+-------------+-------------+-------------+-----------------------------------------------+----+\n",
      "|node_id |name                      |status   |internal_id|address                                                                                        |countries    |country_codes|sourceID     |valid_until                                    |note|\n",
      "+--------+--------------------------+---------+-----------+-----------------------------------------------------------------------------------------------+-------------+-------------+-------------+-----------------------------------------------+----+\n",
      "|11000001|MICHAEL PAPAGEORGE, MR.   |ACTIVE   |10001      |MICHAEL PAPAGEORGE; MR. 106 NICHOLSON STREET BROOKLYN PRETORIA 0002; GAUTENG (PWV) SOUTH AFRICA|South Africa |ZAF          |Panama Papers|The Panama Papers  data is current through 2015|NULL|\n",
      "|11000002|CORFIDUCIA ANSTALT        |ACTIVE   |10004      |NULL                                                                                           |Liechtenstein|LIE          |Panama Papers|The Panama Papers  data is current through 2015|NULL|\n",
      "|11000003|DAVID, RONALD             |SUSPENDED|10014      |NULL                                                                                           |Monaco       |MCO          |Panama Papers|The Panama Papers  data is current through 2015|NULL|\n",
      "|11000004|DE  BOUTSELIS, JEAN-PIERRE|SUSPENDED|10015      |NULL                                                                                           |Belgium      |BEL          |Panama Papers|The Panama Papers  data is current through 2015|NULL|\n",
      "+--------+--------------------------+---------+-----------+-----------------------------------------------------------------------------------------------+-------------+-------------+-------------+-----------------------------------------------+----+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mintermediaryDS\u001b[39m: \u001b[32mDataset\u001b[39m[\u001b[32mIntermediary\u001b[39m] = [node_id: string, name: string ... 8 more fields]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Read CSV and convert to Dataset\n",
    "val intermediaryDS = spark.read\n",
    "  .option(\"header\", \"true\")\n",
    "  .option(\"inferSchema\", \"true\")\n",
    "  .csv(\"full-oldb.LATEST/nodes-intermediaries.csv\")\n",
    "  .as[Intermediary]\n",
    "\n",
    "// Example queries\n",
    "intermediaryDS.show(4, truncate=false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab821122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mclass\u001b[39m \u001b[36mOtherNode\u001b[39m"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// create a case class for the `nodes-intermediaries.csv`\n",
    "/**\n",
    "  * Represents a node from the nodes-others.csv file.\n",
    "  *\n",
    "  * @param node_id The unique identifier for the node.\n",
    "  * @param name The name associated with the node.\n",
    "  * @param `type` The type of the node (e.g., 'company', 'person').\n",
    "  * @param country_codes The country codes associated with the node.\n",
    "  * @param countries The countries associated with the node.\n",
    "  * @param sourceID The ID of the data source.\n",
    "  * @param valid_until The date until which the data is considered valid.\n",
    "  * @param note Any additional notes.\n",
    "  */\n",
    "case class OtherNode(\n",
    "  node_id: String,\n",
    "  name: Option[String],\n",
    "  `type`: Option[String],\n",
    "  country_codes: Option[String],\n",
    "  countries: Option[String],\n",
    "  sourceID: Option[String],\n",
    "  valid_until: Option[String],\n",
    "  note: Option[String]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "156c0a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+------------------+---------------+-----------+------------+------------------------+---------+-------------+--------------------+--------------------+--------------------+\n",
      "| node_id|                name|                type|incorporation_date|struck_off_date|closed_date|jurisdiction|jurisdiction_description|countries|country_codes|            sourceID|         valid_until|                note|\n",
      "+--------+--------------------+--------------------+------------------+---------------+-----------+------------+------------------------+---------+-------------+--------------------+--------------------+--------------------+\n",
      "|85004929|ANTAM ENTERPRISES...|LIMITED LIABILITY...|       18-MAY-1983|           NULL|28-NOV-2012|          AW|                   Aruba|     NULL|         NULL|Paradise Papers -...|Aruba corporate r...|Closed date stand...|\n",
      "|85008443|      DEVIATION N.V.|LIMITED LIABILITY...|       28-JUN-1989|    31-DEC-2002|       NULL|          AW|                   Aruba|     NULL|         NULL|Paradise Papers -...|Aruba corporate r...|                NULL|\n",
      "|85008517|         ARIAZI N.V.|LIMITED LIABILITY...|       19-JUL-1989|           NULL|19-MAY-2004|          AW|                   Aruba|     NULL|         NULL|Paradise Papers -...|Aruba corporate r...|Closed date stand...|\n",
      "|85008542|       FLAIRUBA N.V.|LIMITED LIABILITY...|       27-JUL-1989|    24-JUL-2000|       NULL|          AW|                   Aruba|     NULL|         NULL|Paradise Papers -...|Aruba corporate r...|                NULL|\n",
      "+--------+--------------------+--------------------+------------------+---------------+-----------+------------+------------------------+---------+-------------+--------------------+--------------------+--------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36motherNodeDS\u001b[39m: \u001b[32mDataset\u001b[39m[\u001b[32mOtherNode\u001b[39m] = [node_id: int, name: string ... 11 more fields]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Read CSV and convert to Dataset\n",
    "val otherNodeDS = spark.read\n",
    "  .option(\"header\", \"true\")\n",
    "  .option(\"inferSchema\", \"true\")\n",
    "  .csv(\"full-oldb.LATEST/nodes-others.csv\")\n",
    "  .as[OtherNode]\n",
    "\n",
    "// Example queries\n",
    "otherNodeDS.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e2c4d64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mres9\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"2.13.17\"\u001b[39m"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scala.util.Properties.versionNumberString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb36ea22-2c49-4577-81a6-1ce72d1018b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa140c3-4e17-4190-b71c-b4aca4c0fe8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala 2.13",
   "language": "scala",
   "name": "scala213"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.13.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
