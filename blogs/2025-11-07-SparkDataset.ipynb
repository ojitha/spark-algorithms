{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1363d630-f517-4d8c-bb11-b4d055aec633",
   "metadata": {},
   "source": [
    "---\n",
    "layout: post\n",
    "title:  Spark Dataset APIs\n",
    "date:   2025-11-07\n",
    "categories: [Spark, Scala]\n",
    "mermaid: true\n",
    "maths: true\n",
    "typora-root-url: /Users/ojitha/GitHub/ojitha.github.io\n",
    "typora-copy-images-to: ../../blog/assets/images/${filename}\n",
    "---\n",
    "\n",
    "<style>\n",
    "/* Styles for the two-column layout */\n",
    ".image-text-container {\n",
    "    display: flex; /* Enables flexbox */\n",
    "    flex-wrap: wrap; /* Allows columns to stack on small screens */\n",
    "    gap: 20px; /* Space between the image and text */\n",
    "    align-items: center; /* Vertically centers content in columns */\n",
    "    margin-bottom: 20px; /* Space below this section */\n",
    "}\n",
    "\n",
    ".image-column {\n",
    "    flex: 1; /* Allows this column to grow */\n",
    "    min-width: 250px; /* Minimum width for the image column before stacking */\n",
    "    max-width: 40%; /* Maximum width for the image column to not take up too much space initially */\n",
    "    box-sizing: border-box; /* Include padding/border in element's total width/height */\n",
    "}\n",
    "\n",
    ".text-column {\n",
    "    flex: 2; /* Allows this column to grow more (e.g., twice as much as image-column) */\n",
    "    min-width: 300px; /* Minimum width for the text column before stacking */\n",
    "    box-sizing: border-box;\n",
    "}\n",
    "\n",
    "</style>\n",
    "\n",
    "<div class=\"image-text-container\">\n",
    "    <div class=\"image-column\">\n",
    "        <img src=\"https://raw.githubusercontent.com/ojitha/blog/master/assets/images/2025-10027-Scala-2-Collections/scala-collections-illustration.svg\" alt=\"Scala Functors\" width=\"150\" height=\"150\">\n",
    "    </div>\n",
    "    <div class=\"text-column\">\n",
    "<p>TBC</p>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "<!--more-->\n",
    "\n",
    "------\n",
    "\n",
    "* TOC\n",
    "{:toc}\n",
    "------\n",
    "\n",
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619071eb-808f-4e4e-b45f-617bc367132f",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "### What are Datasets?\n",
    "\n",
    "Apache Spark Datasets are the foundational type in Spark's Structured APIs, providing a **type-safe**, distributed collection of strongly typed JVM objects. While DataFrames are Datasets of type `Row`, Datasets allow you to define custom domain-specific objects that each row will consist of, combining the benefits of RDDs (type safety, custom objects) with the optimizations of DataFrames (Catalyst optimizer, Tungsten execution).\n",
    "\n",
    "**Key Characteristics:**\n",
    "\n",
    "1. **Type Safety**: Compile-time type checking prevents runtime type errors\n",
    "2. **Encoders**: Special serialization mechanism that maps domain-specific types to Spark's internal binary format\n",
    "3. **Catalyst Optimization**: Benefits from Spark SQL's query optimizer\n",
    "4. **JVM Language Feature**: Available only in Scala and Java (not Python or R)\n",
    "5. **Functional API**: Supports functional transformations like `map`, `filter`, `flatMap`\n",
    "\n",
    "**Dataset[T]**: A distributed collection of data elements of type `T`, where `T` is a domain-specific class (case class in Scala, JavaBean in Java) that Spark can encode and optimize.\n",
    "\n",
    "$$\n",
    "\\text{Dataset}[T] = \\{t_1, t_2, \\ldots, t_n\\} \\text{ where } t_i \\in T\n",
    "$$\n",
    "\n",
    "Translation: A Dataset of type T is a collection of n elements, where each element belongs to type T.\n",
    "\n",
    "**Encoder[T]**: A mechanism that converts between JVM objects of type `T` and Spark SQL's internal binary format (InternalRow).\n",
    "\n",
    "$$\n",
    "\\text{Encoder}[T]: T \\leftrightarrow \\text{InternalRow}\n",
    "$$\n",
    "\n",
    "Translation: An Encoder for type T provides bidirectional conversion between objects of type T and Spark's internal row representation.\n",
    "\n",
    "### Mathematical Foundations\n",
    "\n",
    "Datasets embody key functional programming concepts:\n",
    "\n",
    "1. **Functor Laws** (for `map`):\n",
    "    - Identity: `ds.map(x => x) = ds`\n",
    "    - Composition: `ds.map(f).map(g) = ds.map(x => g(f(x)))`\n",
    "\n",
    "2. **Monad Laws** (for `flatMap`):\n",
    "    - Left identity: `Dataset(x).flatMap(f) = f(x)`\n",
    "    - Right identity: `ds.flatMap(x => Dataset(x)) = ds`\n",
    "    - Associativity: `ds.flatMap(f).flatMap(g) = ds.flatMap(x => f(x).flatMap(g))`\n",
    "\n",
    "### Dataset Movie Lens\n",
    "\n",
    "Let's examine the MovieLens dataset: [recommended for education and development](https://grouplens.org/datasets/movielens/){:target=\"_blank\"} for simplicity.\n",
    "\n",
    "```mermaid\n",
    "erDiagram\n",
    "    MOVIES ||--o{ RATINGS : \"receives\"\n",
    "    MOVIES ||--o{ TAGS : \"has\"\n",
    "    MOVIES ||--|| LINKS : \"references\"\n",
    "    \n",
    "    MOVIES {\n",
    "        int movieId PK \"Primary Key\"\n",
    "        string title \"Movie title with year\"\n",
    "        string genres \"Pipe-separated genres\"\n",
    "    }\n",
    "    \n",
    "    RATINGS {\n",
    "        int userId FK \"Foreign Key to User\"\n",
    "        int movieId FK \"Foreign Key to Movie\"\n",
    "        float rating \"Rating value (0.5-5.0)\"\n",
    "        long timestamp \"Unix timestamp\"\n",
    "    }\n",
    "    \n",
    "    TAGS {\n",
    "        int userId FK \"Foreign Key to User\"\n",
    "        int movieId FK \"Foreign Key to Movie\"\n",
    "        string tag \"User-generated tag\"\n",
    "        long timestamp \"Unix timestamp\"\n",
    "    }\n",
    "    \n",
    "    LINKS {\n",
    "        int movieId PK \"Primary Key\"\n",
    "        int movieId FK \"Foreign Key to Movie\"\n",
    "        string imdbId \"IMDB identifier\"\n",
    "        string tmdbId \"TMDB identifier\"\n",
    "    }\n",
    "```\n",
    "\n",
    "#### **Entities and Attributes:**\n",
    "\n",
    "1.  **MOVIES** (9,742 movies)\n",
    "    -   `movieId` (Primary Key)\n",
    "    -   `title` (includes release year)\n",
    "    -   `genres` (pipe-separated list)\n",
    "2.  **RATINGS** (100,836 ratings)\n",
    "    -   `userId` (Foreign Key)\n",
    "    -   `movieId` (Foreign Key)\n",
    "    -   `rating` (0.5 to 5.0 stars)\n",
    "    -   `timestamp` (Unix timestamp)\n",
    "3.  **TAGS** (3,683 tags)\n",
    "    -   `userId` (Foreign Key)\n",
    "    -   `movieId` (Foreign Key)\n",
    "    -   `tag` (user-generated metadata)\n",
    "    -   `timestamp` (Unix timestamp)\n",
    "4.  **LINKS** (9,742 links)\n",
    "    -   `movieId` (Primary Key & Foreign Key)\n",
    "    -   `imdbId` (IMDB identifier)\n",
    "    -   `tmdbId` (The Movie Database identifier)\n",
    "\n",
    "#### **Relationships:**\n",
    "\n",
    "-   **MOVIES ↔ RATINGS**: One-to-Many (a movie can have multiple ratings)\n",
    "-   **MOVIES ↔ TAGS**: One-to-Many (a movie can have multiple tags)\n",
    "-   **MOVIES ↔ LINKS**: One-to-One (each movie has one set of external links)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b84bbeb-778c-49de-88c8-82a8ec31f328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.log4j.{Level, Logger}\u001b[39m"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  // Configure Coursier to fetch doc JARs\n",
    "  interp.repositories() ++= Seq(\n",
    "    coursierapi.MavenRepository.of(\"https://repo1.maven.org/maven2\")\n",
    "  )\n",
    "\n",
    "  // Enable compiler to use Java classpath (REMOVED the invalid doc.value line)\n",
    "  interp.configureCompiler(c => {\n",
    "    c.settings.usejavacp.value = true\n",
    "  })\n",
    "\n",
    "  // Import Spark\n",
    "import $ivy.`org.apache.spark::spark-sql:3.3.1` // Or use any other 2.x version here\n",
    "\n",
    "import org.apache.log4j.{Level, Logger}\n",
    "Logger.getLogger(\"org\").setLevel(Level.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d061574b-1b6c-4d45-a99c-d3a88690f56c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Loading <code>spark-stubs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Getting spark JARs\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Creating SparkSession\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SLF4J: Class path contains multiple SLF4J bindings.\n",
      "SLF4J: Found binding in [jar:file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/logging/log4j/log4j-slf4j-impl/2.17.2/log4j-slf4j-impl-2.17.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: Found binding in [jar:file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/org/slf4j/slf4j-log4j12/1.7.30/slf4j-log4j12-1.7.30.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
      "SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/11/07 08:53:26 INFO SparkContext: Running Spark version 3.3.1\n",
      "25/11/07 08:53:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/11/07 08:53:26 INFO ResourceUtils: ==============================================================\n",
      "25/11/07 08:53:26 INFO ResourceUtils: No custom resources configured for spark.driver.\n",
      "25/11/07 08:53:26 INFO ResourceUtils: ==============================================================\n",
      "25/11/07 08:53:26 INFO SparkContext: Submitted application: 3a937c9f-e2c5-4d0f-ab7a-f44bbdb083d2\n",
      "25/11/07 08:53:26 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)\n",
      "25/11/07 08:53:26 INFO ResourceProfile: Limiting resource is cpu\n",
      "25/11/07 08:53:26 INFO ResourceProfileManager: Added ResourceProfile id: 0\n",
      "25/11/07 08:53:26 INFO SecurityManager: Changing view acls to: jovyan\n",
      "25/11/07 08:53:26 INFO SecurityManager: Changing modify acls to: jovyan\n",
      "25/11/07 08:53:26 INFO SecurityManager: Changing view acls groups to: \n",
      "25/11/07 08:53:26 INFO SecurityManager: Changing modify acls groups to: \n",
      "25/11/07 08:53:26 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(jovyan); groups with view permissions: Set(); users  with modify permissions: Set(jovyan); groups with modify permissions: Set()\n",
      "25/11/07 08:53:27 INFO Utils: Successfully started service 'sparkDriver' on port 37383.\n",
      "25/11/07 08:53:27 INFO SparkEnv: Registering MapOutputTracker\n",
      "25/11/07 08:53:27 INFO SparkEnv: Registering BlockManagerMaster\n",
      "25/11/07 08:53:27 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\n",
      "25/11/07 08:53:27 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up\n",
      "25/11/07 08:53:27 INFO SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "25/11/07 08:53:27 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-3ae08066-b09b-430b-9674-ff0f87a03a85\n",
      "25/11/07 08:53:27 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB\n",
      "25/11/07 08:53:27 INFO SparkEnv: Registering OutputCommitCoordinator\n",
      "25/11/07 08:53:28 INFO Utils: Successfully started service 'SparkUI' on port 4040.\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/jitpack.io/com/github/jupyter/jvm-repr/0.4.0/jvm-repr-0.4.0.jar at spark://fad0f522f137:37383/jars/jvm-repr-0.4.0.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/com/github/javaparser/javaparser-core/3.2.12/javaparser-core-3.2.12.jar at spark://fad0f522f137:37383/jars/javaparser-core-3.2.12.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/ammonite-compiler-interface_2.12.20/3.0.2/ammonite-compiler-interface_2.12.20-3.0.2.jar at spark://fad0f522f137:37383/jars/ammonite-compiler-interface_2.12.20-3.0.2.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/ammonite-compiler_2.12.20/3.0.2/ammonite-compiler_2.12.20-3.0.2.jar at spark://fad0f522f137:37383/jars/ammonite-compiler_2.12.20-3.0.2.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/ammonite-interp-api_2.12.20/3.0.2/ammonite-interp-api_2.12.20-3.0.2.jar at spark://fad0f522f137:37383/jars/ammonite-interp-api_2.12.20-3.0.2.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/ammonite-repl-api_2.12.20/3.0.2/ammonite-repl-api_2.12.20-3.0.2.jar at spark://fad0f522f137:37383/jars/ammonite-repl-api_2.12.20-3.0.2.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/ammonite-util_2.12/3.0.2/ammonite-util_2.12-3.0.2.jar at spark://fad0f522f137:37383/jars/ammonite-util_2.12-3.0.2.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/fansi_2.12/0.5.0/fansi_2.12-0.5.0.jar at spark://fad0f522f137:37383/jars/fansi_2.12-0.5.0.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/fastparse_2.12/3.1.1/fastparse_2.12-3.1.1.jar at spark://fad0f522f137:37383/jars/fastparse_2.12-3.1.1.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/geny_2.12/1.1.1/geny_2.12-1.1.1.jar at spark://fad0f522f137:37383/jars/geny_2.12-1.1.1.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/mainargs_2.12/0.7.6/mainargs_2.12-0.7.6.jar at spark://fad0f522f137:37383/jars/mainargs_2.12-0.7.6.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/os-lib_2.12/0.11.3/os-lib_2.12-0.11.3.jar at spark://fad0f522f137:37383/jars/os-lib_2.12-0.11.3.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/pprint_2.12/0.9.0/pprint_2.12-0.9.0.jar at spark://fad0f522f137:37383/jars/pprint_2.12-0.9.0.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/scalaparse_2.12/3.1.1/scalaparse_2.12-3.1.1.jar at spark://fad0f522f137:37383/jars/scalaparse_2.12-3.1.1.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/sourcecode_2.12/0.4.3-M5/sourcecode_2.12-0.4.3-M5.jar at spark://fad0f522f137:37383/jars/sourcecode_2.12-0.4.3-M5.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/io/get-coursier/interface/1.0.29-M1/interface-1.0.29-M1.jar at spark://fad0f522f137:37383/jars/interface-1.0.29-M1.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/org/javassist/javassist/3.21.0-GA/javassist-3.21.0-GA.jar at spark://fad0f522f137:37383/jars/javassist-3.21.0-GA.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/org/scala-lang/modules/scala-collection-compat_2.12/2.13.0/scala-collection-compat_2.12-2.13.0.jar at spark://fad0f522f137:37383/jars/scala-collection-compat_2.12-2.13.0.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/org/tpolecat/typename_2.12/1.1.0/typename_2.12-1.1.0.jar at spark://fad0f522f137:37383/jars/typename_2.12-1.1.0.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/sh/almond/interpreter-api_2.12/0.14.1/interpreter-api_2.12-0.14.1.jar at spark://fad0f522f137:37383/jars/interpreter-api_2.12-0.14.1.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/sh/almond/jupyter-api_2.12/0.14.1/jupyter-api_2.12-0.14.1.jar at spark://fad0f522f137:37383/jars/jupyter-api_2.12-0.14.1.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/sh/almond/scala-kernel-api_2.12.20/0.14.1/scala-kernel-api_2.12.20-0.14.1.jar at spark://fad0f522f137:37383/jars/scala-kernel-api_2.12.20-0.14.1.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.local/share/jupyter/kernels/scala212/launcher.jar at spark://fad0f522f137:37383/jars/launcher.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/org/scala-lang/scala-library/2.12.17/scala-library-2.12.17.jar at spark://fad0f522f137:37383/jars/scala-library-2.12.17.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-sql_2.12/3.2.0/spark-sql_2.12-3.2.0.jar at spark://fad0f522f137:37383/jars/spark-sql_2.12-3.2.0.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-sketch_2.12/3.2.0/spark-sketch_2.12-3.2.0.jar at spark://fad0f522f137:37383/jars/spark-sketch_2.12-3.2.0.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-core_2.12/3.2.0/spark-core_2.12-3.2.0.jar at spark://fad0f522f137:37383/jars/spark-core_2.12-3.2.0.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-catalyst_2.12/3.2.0/spark-catalyst_2.12-3.2.0.jar at spark://fad0f522f137:37383/jars/spark-catalyst_2.12-3.2.0.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-tags_2.12/3.2.0/spark-tags_2.12-3.2.0.jar at spark://fad0f522f137:37383/jars/spark-tags_2.12-3.2.0.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/orc/orc-core/1.6.11/orc-core-1.6.11.jar at spark://fad0f522f137:37383/jars/orc-core-1.6.11.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/orc/orc-mapreduce/1.6.11/orc-mapreduce-1.6.11.jar at spark://fad0f522f137:37383/jars/orc-mapreduce-1.6.11.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/parquet/parquet-column/1.12.1/parquet-column-1.12.1.jar at spark://fad0f522f137:37383/jars/parquet-column-1.12.1.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/parquet/parquet-hadoop/1.12.1/parquet-hadoop-1.12.1.jar at spark://fad0f522f137:37383/jars/parquet-hadoop-1.12.1.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/com/fasterxml/jackson/core/jackson-databind/2.12.3/jackson-databind-2.12.3.jar at spark://fad0f522f137:37383/jars/jackson-databind-2.12.3.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/avro/avro/1.10.2/avro-1.10.2.jar at spark://fad0f522f137:37383/jars/avro-1.10.2.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/avro/avro-mapred/1.10.2/avro-mapred-1.10.2.jar at spark://fad0f522f137:37383/jars/avro-mapred-1.10.2.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/hadoop/hadoop-client-api/3.3.1/hadoop-client-api-3.3.1.jar at spark://fad0f522f137:37383/jars/hadoop-client-api-3.3.1.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar at spark://fad0f522f137:37383/jars/hadoop-client-runtime-3.3.1.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-launcher_2.12/3.2.0/spark-launcher_2.12-3.2.0.jar at spark://fad0f522f137:37383/jars/spark-launcher_2.12-3.2.0.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-kvstore_2.12/3.2.0/spark-kvstore_2.12-3.2.0.jar at spark://fad0f522f137:37383/jars/spark-kvstore_2.12-3.2.0.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-network-common_2.12/3.2.0/spark-network-common_2.12-3.2.0.jar at spark://fad0f522f137:37383/jars/spark-network-common_2.12-3.2.0.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-network-shuffle_2.12/3.2.0/spark-network-shuffle_2.12-3.2.0.jar at spark://fad0f522f137:37383/jars/spark-network-shuffle_2.12-3.2.0.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.12/3.2.0/spark-unsafe_2.12-3.2.0.jar at spark://fad0f522f137:37383/jars/spark-unsafe_2.12-3.2.0.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/commons/commons-math3/3.4.1/commons-math3-3.4.1.jar at spark://fad0f522f137:37383/jars/commons-math3-3.4.1.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/commons/commons-text/1.6/commons-text-1.6.jar at spark://fad0f522f137:37383/jars/commons-text-1.6.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/commons-io/commons-io/2.8.0/commons-io-2.8.0.jar at spark://fad0f522f137:37383/jars/commons-io-2.8.0.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/org/slf4j/slf4j-api/1.7.30/slf4j-api-1.7.30.jar at spark://fad0f522f137:37383/jars/slf4j-api-1.7.30.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/org/slf4j/jul-to-slf4j/1.7.30/jul-to-slf4j-1.7.30.jar at spark://fad0f522f137:37383/jars/jul-to-slf4j-1.7.30.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/org/slf4j/jcl-over-slf4j/1.7.30/jcl-over-slf4j-1.7.30.jar at spark://fad0f522f137:37383/jars/jcl-over-slf4j-1.7.30.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/log4j/log4j/1.2.17/log4j-1.2.17.jar at spark://fad0f522f137:37383/jars/log4j-1.2.17.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/org/slf4j/slf4j-log4j12/1.7.30/slf4j-log4j12-1.7.30.jar at spark://fad0f522f137:37383/jars/slf4j-log4j12-1.7.30.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/com/ning/compress-lzf/1.0.3/compress-lzf-1.0.3.jar at spark://fad0f522f137:37383/jars/compress-lzf-1.0.3.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/org/lz4/lz4-java/1.7.1/lz4-java-1.7.1.jar at spark://fad0f522f137:37383/jars/lz4-java-1.7.1.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/com/github/luben/zstd-jni/1.5.0-4/zstd-jni-1.5.0-4.jar at spark://fad0f522f137:37383/jars/zstd-jni-1.5.0-4.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/org/roaringbitmap/RoaringBitmap/0.9.0/RoaringBitmap-0.9.0.jar at spark://fad0f522f137:37383/jars/RoaringBitmap-0.9.0.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/commons-net/commons-net/3.1/commons-net-3.1.jar at spark://fad0f522f137:37383/jars/commons-net-3.1.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/org/glassfish/jersey/core/jersey-client/2.34/jersey-client-2.34.jar at spark://fad0f522f137:37383/jars/jersey-client-2.34.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/org/glassfish/jersey/core/jersey-common/2.34/jersey-common-2.34.jar at spark://fad0f522f137:37383/jars/jersey-common-2.34.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/org/glassfish/jersey/core/jersey-server/2.34/jersey-server-2.34.jar at spark://fad0f522f137:37383/jars/jersey-server-2.34.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/org/glassfish/jersey/containers/jersey-container-servlet/2.34/jersey-container-servlet-2.34.jar at spark://fad0f522f137:37383/jars/jersey-container-servlet-2.34.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/org/glassfish/jersey/containers/jersey-container-servlet-core/2.34/jersey-container-servlet-core-2.34.jar at spark://fad0f522f137:37383/jars/jersey-container-servlet-core-2.34.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/org/glassfish/jersey/inject/jersey-hk2/2.34/jersey-hk2-2.34.jar at spark://fad0f522f137:37383/jars/jersey-hk2-2.34.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/io/netty/netty-all/4.1.68.Final/netty-all-4.1.68.Final.jar at spark://fad0f522f137:37383/jars/netty-all-4.1.68.Final.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/io/dropwizard/metrics/metrics-core/4.2.0/metrics-core-4.2.0.jar at spark://fad0f522f137:37383/jars/metrics-core-4.2.0.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/io/dropwizard/metrics/metrics-jvm/4.2.0/metrics-jvm-4.2.0.jar at spark://fad0f522f137:37383/jars/metrics-jvm-4.2.0.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/io/dropwizard/metrics/metrics-json/4.2.0/metrics-json-4.2.0.jar at spark://fad0f522f137:37383/jars/metrics-json-4.2.0.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/io/dropwizard/metrics/metrics-graphite/4.2.0/metrics-graphite-4.2.0.jar at spark://fad0f522f137:37383/jars/metrics-graphite-4.2.0.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/io/dropwizard/metrics/metrics-jmx/4.2.0/metrics-jmx-4.2.0.jar at spark://fad0f522f137:37383/jars/metrics-jmx-4.2.0.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/com/fasterxml/jackson/module/jackson-module-scala_2.12/2.12.3/jackson-module-scala_2.12-2.12.3.jar at spark://fad0f522f137:37383/jars/jackson-module-scala_2.12-2.12.3.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/net/razorvine/pyrolite/4.30/pyrolite-4.30.jar at spark://fad0f522f137:37383/jars/pyrolite-4.30.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/net/sf/py4j/py4j/0.10.9.2/py4j-0.10.9.2.jar at spark://fad0f522f137:37383/jars/py4j-0.10.9.2.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/javax/xml/bind/jaxb-api/2.2.11/jaxb-api-2.2.11.jar at spark://fad0f522f137:37383/jars/jaxb-api-2.2.11.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/arrow/arrow-vector/2.0.0/arrow-vector-2.0.0.jar at spark://fad0f522f137:37383/jars/arrow-vector-2.0.0.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/arrow/arrow-memory-netty/2.0.0/arrow-memory-netty-2.0.0.jar at spark://fad0f522f137:37383/jars/arrow-memory-netty-2.0.0.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/orc/orc-shims/1.6.11/orc-shims-1.6.11.jar at spark://fad0f522f137:37383/jars/orc-shims-1.6.11.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/parquet/parquet-common/1.12.1/parquet-common-1.12.1.jar at spark://fad0f522f137:37383/jars/parquet-common-1.12.1.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/parquet/parquet-encoding/1.12.1/parquet-encoding-1.12.1.jar at spark://fad0f522f137:37383/jars/parquet-encoding-1.12.1.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/parquet/parquet-format-structures/1.12.1/parquet-format-structures-1.12.1.jar at spark://fad0f522f137:37383/jars/parquet-format-structures-1.12.1.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/parquet/parquet-jackson/1.12.1/parquet-jackson-1.12.1.jar at spark://fad0f522f137:37383/jars/parquet-jackson-1.12.1.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/com/fasterxml/jackson/core/jackson-annotations/2.12.3/jackson-annotations-2.12.3.jar at spark://fad0f522f137:37383/jars/jackson-annotations-2.12.3.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/com/fasterxml/jackson/core/jackson-core/2.12.3/jackson-core-2.12.3.jar at spark://fad0f522f137:37383/jars/jackson-core-2.12.3.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/avro/avro-ipc/1.10.2/avro-ipc-1.10.2.jar at spark://fad0f522f137:37383/jars/avro-ipc-1.10.2.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar at spark://fad0f522f137:37383/jars/htrace-core4-4.1.0-incubating.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/com/google/crypto/tink/tink/1.6.0/tink-1.6.0.jar at spark://fad0f522f137:37383/jars/tink-1.6.0.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/org/roaringbitmap/shims/0.9.0/shims-0.9.0.jar at spark://fad0f522f137:37383/jars/shims-0.9.0.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/arrow/arrow-format/2.0.0/arrow-format-2.0.0.jar at spark://fad0f522f137:37383/jars/arrow-format-2.0.0.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/arrow/arrow-memory-core/2.0.0/arrow-memory-core-2.0.0.jar at spark://fad0f522f137:37383/jars/arrow-memory-core-2.0.0.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO SparkContext: Added JAR file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/com/google/flatbuffers/flatbuffers-java/1.9.0/flatbuffers-java-1.9.0.jar at spark://fad0f522f137:37383/jars/flatbuffers-java-1.9.0.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO Executor: Starting executor ID driver on host fad0f522f137\n",
      "25/11/07 08:53:28 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''\n",
      "25/11/07 08:53:28 INFO Executor: Using REPL class URI: spark://fad0f522f137:37383/classes\n",
      "25/11/07 08:53:28 INFO Executor: Fetching spark://fad0f522f137:37383/jars/compress-lzf-1.0.3.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO TransportClientFactory: Successfully created connection to fad0f522f137/172.18.0.2:37383 after 141 ms (0 ms spent in bootstraps)\n",
      "25/11/07 08:53:28 INFO Utils: Fetching spark://fad0f522f137:37383/jars/compress-lzf-1.0.3.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp8238558989519031190.tmp\n",
      "25/11/07 08:53:28 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/compress-lzf-1.0.3.jar to class loader\n",
      "25/11/07 08:53:28 INFO Executor: Fetching spark://fad0f522f137:37383/jars/parquet-format-structures-1.12.1.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:28 INFO Utils: Fetching spark://fad0f522f137:37383/jars/parquet-format-structures-1.12.1.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp511414255807418385.tmp\n",
      "25/11/07 08:53:29 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/parquet-format-structures-1.12.1.jar to class loader\n",
      "25/11/07 08:53:29 INFO Executor: Fetching spark://fad0f522f137:37383/jars/typename_2.12-1.1.0.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:29 INFO Utils: Fetching spark://fad0f522f137:37383/jars/typename_2.12-1.1.0.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp7746774640393725429.tmp\n",
      "25/11/07 08:53:29 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/typename_2.12-1.1.0.jar to class loader\n",
      "25/11/07 08:53:29 INFO Executor: Fetching spark://fad0f522f137:37383/jars/jersey-server-2.34.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:29 INFO Utils: Fetching spark://fad0f522f137:37383/jars/jersey-server-2.34.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp6199212787019440964.tmp\n",
      "25/11/07 08:53:29 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/jersey-server-2.34.jar to class loader\n",
      "25/11/07 08:53:29 INFO Executor: Fetching spark://fad0f522f137:37383/jars/flatbuffers-java-1.9.0.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:29 INFO Utils: Fetching spark://fad0f522f137:37383/jars/flatbuffers-java-1.9.0.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp8899745614785975123.tmp\n",
      "25/11/07 08:53:29 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/flatbuffers-java-1.9.0.jar to class loader\n",
      "25/11/07 08:53:29 INFO Executor: Fetching spark://fad0f522f137:37383/jars/tink-1.6.0.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:29 INFO Utils: Fetching spark://fad0f522f137:37383/jars/tink-1.6.0.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp1670985531944263581.tmp\n",
      "25/11/07 08:53:29 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/tink-1.6.0.jar to class loader\n",
      "25/11/07 08:53:29 INFO Executor: Fetching spark://fad0f522f137:37383/jars/hadoop-client-runtime-3.3.1.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:29 INFO Utils: Fetching spark://fad0f522f137:37383/jars/hadoop-client-runtime-3.3.1.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp882192242976990323.tmp\n",
      "25/11/07 08:53:29 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/hadoop-client-runtime-3.3.1.jar to class loader\n",
      "25/11/07 08:53:29 INFO Executor: Fetching spark://fad0f522f137:37383/jars/arrow-memory-core-2.0.0.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:29 INFO Utils: Fetching spark://fad0f522f137:37383/jars/arrow-memory-core-2.0.0.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp1690895208982497893.tmp\n",
      "25/11/07 08:53:29 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/arrow-memory-core-2.0.0.jar to class loader\n",
      "25/11/07 08:53:29 INFO Executor: Fetching spark://fad0f522f137:37383/jars/javaparser-core-3.2.12.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:29 INFO Utils: Fetching spark://fad0f522f137:37383/jars/javaparser-core-3.2.12.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp4337850741580365955.tmp\n",
      "25/11/07 08:53:29 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/javaparser-core-3.2.12.jar to class loader\n",
      "25/11/07 08:53:29 INFO Executor: Fetching spark://fad0f522f137:37383/jars/commons-io-2.8.0.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:29 INFO Utils: Fetching spark://fad0f522f137:37383/jars/commons-io-2.8.0.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp6623226146900442581.tmp\n",
      "25/11/07 08:53:29 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/commons-io-2.8.0.jar to class loader\n",
      "25/11/07 08:53:29 INFO Executor: Fetching spark://fad0f522f137:37383/jars/jersey-client-2.34.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:29 INFO Utils: Fetching spark://fad0f522f137:37383/jars/jersey-client-2.34.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp1011048528914398551.tmp\n",
      "25/11/07 08:53:29 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/jersey-client-2.34.jar to class loader\n",
      "25/11/07 08:53:29 INFO Executor: Fetching spark://fad0f522f137:37383/jars/jersey-hk2-2.34.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:29 INFO Utils: Fetching spark://fad0f522f137:37383/jars/jersey-hk2-2.34.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp3370930040220502658.tmp\n",
      "25/11/07 08:53:29 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/jersey-hk2-2.34.jar to class loader\n",
      "25/11/07 08:53:29 INFO Executor: Fetching spark://fad0f522f137:37383/jars/jul-to-slf4j-1.7.30.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:29 INFO Utils: Fetching spark://fad0f522f137:37383/jars/jul-to-slf4j-1.7.30.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp3604280586601273662.tmp\n",
      "25/11/07 08:53:29 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/jul-to-slf4j-1.7.30.jar to class loader\n",
      "25/11/07 08:53:29 INFO Executor: Fetching spark://fad0f522f137:37383/jars/os-lib_2.12-0.11.3.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:29 INFO Utils: Fetching spark://fad0f522f137:37383/jars/os-lib_2.12-0.11.3.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp3463656412239179277.tmp\n",
      "25/11/07 08:53:29 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/os-lib_2.12-0.11.3.jar to class loader\n",
      "25/11/07 08:53:29 INFO Executor: Fetching spark://fad0f522f137:37383/jars/spark-unsafe_2.12-3.2.0.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:29 INFO Utils: Fetching spark://fad0f522f137:37383/jars/spark-unsafe_2.12-3.2.0.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp4760046794111929946.tmp\n",
      "25/11/07 08:53:29 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/spark-unsafe_2.12-3.2.0.jar to class loader\n",
      "25/11/07 08:53:29 INFO Executor: Fetching spark://fad0f522f137:37383/jars/shims-0.9.0.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:29 INFO Utils: Fetching spark://fad0f522f137:37383/jars/shims-0.9.0.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp3235571862618458131.tmp\n",
      "25/11/07 08:53:29 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/shims-0.9.0.jar to class loader\n",
      "25/11/07 08:53:29 INFO Executor: Fetching spark://fad0f522f137:37383/jars/metrics-jmx-4.2.0.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:29 INFO Utils: Fetching spark://fad0f522f137:37383/jars/metrics-jmx-4.2.0.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp3022514299467920569.tmp\n",
      "25/11/07 08:53:29 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/metrics-jmx-4.2.0.jar to class loader\n",
      "25/11/07 08:53:29 INFO Executor: Fetching spark://fad0f522f137:37383/jars/parquet-jackson-1.12.1.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:29 INFO Utils: Fetching spark://fad0f522f137:37383/jars/parquet-jackson-1.12.1.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp1413049734101524914.tmp\n",
      "25/11/07 08:53:29 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/parquet-jackson-1.12.1.jar to class loader\n",
      "25/11/07 08:53:29 INFO Executor: Fetching spark://fad0f522f137:37383/jars/jackson-annotations-2.12.3.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:29 INFO Utils: Fetching spark://fad0f522f137:37383/jars/jackson-annotations-2.12.3.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp8425044152830555780.tmp\n",
      "25/11/07 08:53:29 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/jackson-annotations-2.12.3.jar to class loader\n",
      "25/11/07 08:53:29 INFO Executor: Fetching spark://fad0f522f137:37383/jars/slf4j-api-1.7.30.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:29 INFO Utils: Fetching spark://fad0f522f137:37383/jars/slf4j-api-1.7.30.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp6907957238858479673.tmp\n",
      "25/11/07 08:53:29 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/slf4j-api-1.7.30.jar to class loader\n",
      "25/11/07 08:53:29 INFO Executor: Fetching spark://fad0f522f137:37383/jars/spark-core_2.12-3.2.0.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:29 INFO Utils: Fetching spark://fad0f522f137:37383/jars/spark-core_2.12-3.2.0.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp1691979795793690361.tmp\n",
      "25/11/07 08:53:30 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/spark-core_2.12-3.2.0.jar to class loader\n",
      "25/11/07 08:53:30 INFO Executor: Fetching spark://fad0f522f137:37383/jars/metrics-graphite-4.2.0.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:30 INFO Utils: Fetching spark://fad0f522f137:37383/jars/metrics-graphite-4.2.0.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp4887829677138769425.tmp\n",
      "25/11/07 08:53:30 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/metrics-graphite-4.2.0.jar to class loader\n",
      "25/11/07 08:53:30 INFO Executor: Fetching spark://fad0f522f137:37383/jars/scala-library-2.12.17.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:30 INFO Utils: Fetching spark://fad0f522f137:37383/jars/scala-library-2.12.17.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp582187600784184442.tmp\n",
      "25/11/07 08:53:30 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/scala-library-2.12.17.jar to class loader\n",
      "25/11/07 08:53:30 INFO Executor: Fetching spark://fad0f522f137:37383/jars/avro-1.10.2.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:30 INFO Utils: Fetching spark://fad0f522f137:37383/jars/avro-1.10.2.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp1229882173519833142.tmp\n",
      "25/11/07 08:53:30 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/avro-1.10.2.jar to class loader\n",
      "25/11/07 08:53:30 INFO Executor: Fetching spark://fad0f522f137:37383/jars/log4j-1.2.17.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:30 INFO Utils: Fetching spark://fad0f522f137:37383/jars/log4j-1.2.17.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp3788118209828061002.tmp\n",
      "25/11/07 08:53:30 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/log4j-1.2.17.jar to class loader\n",
      "25/11/07 08:53:30 INFO Executor: Fetching spark://fad0f522f137:37383/jars/ammonite-interp-api_2.12.20-3.0.2.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:30 INFO Utils: Fetching spark://fad0f522f137:37383/jars/ammonite-interp-api_2.12.20-3.0.2.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp860893296965333722.tmp\n",
      "25/11/07 08:53:30 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/ammonite-interp-api_2.12.20-3.0.2.jar to class loader\n",
      "25/11/07 08:53:30 INFO Executor: Fetching spark://fad0f522f137:37383/jars/fastparse_2.12-3.1.1.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:30 INFO Utils: Fetching spark://fad0f522f137:37383/jars/fastparse_2.12-3.1.1.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp7798417179988804798.tmp\n",
      "25/11/07 08:53:30 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fastparse_2.12-3.1.1.jar to class loader\n",
      "25/11/07 08:53:30 INFO Executor: Fetching spark://fad0f522f137:37383/jars/jackson-module-scala_2.12-2.12.3.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:30 INFO Utils: Fetching spark://fad0f522f137:37383/jars/jackson-module-scala_2.12-2.12.3.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp1603578126193769450.tmp\n",
      "25/11/07 08:53:30 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/jackson-module-scala_2.12-2.12.3.jar to class loader\n",
      "25/11/07 08:53:30 INFO Executor: Fetching spark://fad0f522f137:37383/jars/avro-mapred-1.10.2.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:30 INFO Utils: Fetching spark://fad0f522f137:37383/jars/avro-mapred-1.10.2.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp6735821965456258436.tmp\n",
      "25/11/07 08:53:30 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/avro-mapred-1.10.2.jar to class loader\n",
      "25/11/07 08:53:30 INFO Executor: Fetching spark://fad0f522f137:37383/jars/ammonite-compiler-interface_2.12.20-3.0.2.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:30 INFO Utils: Fetching spark://fad0f522f137:37383/jars/ammonite-compiler-interface_2.12.20-3.0.2.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp61655507931489730.tmp\n",
      "25/11/07 08:53:30 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/ammonite-compiler-interface_2.12.20-3.0.2.jar to class loader\n",
      "25/11/07 08:53:30 INFO Executor: Fetching spark://fad0f522f137:37383/jars/zstd-jni-1.5.0-4.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:30 INFO Utils: Fetching spark://fad0f522f137:37383/jars/zstd-jni-1.5.0-4.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp4637067418123205890.tmp\n",
      "25/11/07 08:53:30 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/zstd-jni-1.5.0-4.jar to class loader\n",
      "25/11/07 08:53:30 INFO Executor: Fetching spark://fad0f522f137:37383/jars/scala-collection-compat_2.12-2.13.0.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:30 INFO Utils: Fetching spark://fad0f522f137:37383/jars/scala-collection-compat_2.12-2.13.0.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp201914735937856211.tmp\n",
      "25/11/07 08:53:30 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/scala-collection-compat_2.12-2.13.0.jar to class loader\n",
      "25/11/07 08:53:30 INFO Executor: Fetching spark://fad0f522f137:37383/jars/interpreter-api_2.12-0.14.1.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:30 INFO Utils: Fetching spark://fad0f522f137:37383/jars/interpreter-api_2.12-0.14.1.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp839609994658449000.tmp\n",
      "25/11/07 08:53:30 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/interpreter-api_2.12-0.14.1.jar to class loader\n",
      "25/11/07 08:53:30 INFO Executor: Fetching spark://fad0f522f137:37383/jars/mainargs_2.12-0.7.6.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:30 INFO Utils: Fetching spark://fad0f522f137:37383/jars/mainargs_2.12-0.7.6.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp5173129360559595218.tmp\n",
      "25/11/07 08:53:30 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/mainargs_2.12-0.7.6.jar to class loader\n",
      "25/11/07 08:53:30 INFO Executor: Fetching spark://fad0f522f137:37383/jars/jcl-over-slf4j-1.7.30.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:30 INFO Utils: Fetching spark://fad0f522f137:37383/jars/jcl-over-slf4j-1.7.30.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp480829999892406052.tmp\n",
      "25/11/07 08:53:30 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/jcl-over-slf4j-1.7.30.jar to class loader\n",
      "25/11/07 08:53:30 INFO Executor: Fetching spark://fad0f522f137:37383/jars/metrics-json-4.2.0.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:30 INFO Utils: Fetching spark://fad0f522f137:37383/jars/metrics-json-4.2.0.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp6001278633108817020.tmp\n",
      "25/11/07 08:53:30 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/metrics-json-4.2.0.jar to class loader\n",
      "25/11/07 08:53:30 INFO Executor: Fetching spark://fad0f522f137:37383/jars/spark-network-shuffle_2.12-3.2.0.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:30 INFO Utils: Fetching spark://fad0f522f137:37383/jars/spark-network-shuffle_2.12-3.2.0.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp5237942680063757168.tmp\n",
      "25/11/07 08:53:30 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/spark-network-shuffle_2.12-3.2.0.jar to class loader\n",
      "25/11/07 08:53:30 INFO Executor: Fetching spark://fad0f522f137:37383/jars/geny_2.12-1.1.1.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:30 INFO Utils: Fetching spark://fad0f522f137:37383/jars/geny_2.12-1.1.1.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp3236710770533116549.tmp\n",
      "25/11/07 08:53:30 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/geny_2.12-1.1.1.jar to class loader\n",
      "25/11/07 08:53:30 INFO Executor: Fetching spark://fad0f522f137:37383/jars/spark-catalyst_2.12-3.2.0.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:30 INFO Utils: Fetching spark://fad0f522f137:37383/jars/spark-catalyst_2.12-3.2.0.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp9112596996985221934.tmp\n",
      "25/11/07 08:53:30 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/spark-catalyst_2.12-3.2.0.jar to class loader\n",
      "25/11/07 08:53:30 INFO Executor: Fetching spark://fad0f522f137:37383/jars/launcher.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:30 INFO Utils: Fetching spark://fad0f522f137:37383/jars/launcher.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp6429132157564400867.tmp\n",
      "25/11/07 08:53:30 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/launcher.jar to class loader\n",
      "25/11/07 08:53:30 INFO Executor: Fetching spark://fad0f522f137:37383/jars/pprint_2.12-0.9.0.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:30 INFO Utils: Fetching spark://fad0f522f137:37383/jars/pprint_2.12-0.9.0.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp3902008992829847103.tmp\n",
      "25/11/07 08:53:30 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/pprint_2.12-0.9.0.jar to class loader\n",
      "25/11/07 08:53:30 INFO Executor: Fetching spark://fad0f522f137:37383/jars/metrics-core-4.2.0.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:30 INFO Utils: Fetching spark://fad0f522f137:37383/jars/metrics-core-4.2.0.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp3235517862746311887.tmp\n",
      "25/11/07 08:53:30 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/metrics-core-4.2.0.jar to class loader\n",
      "25/11/07 08:53:30 INFO Executor: Fetching spark://fad0f522f137:37383/jars/py4j-0.10.9.2.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:30 INFO Utils: Fetching spark://fad0f522f137:37383/jars/py4j-0.10.9.2.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp5223040651591108560.tmp\n",
      "25/11/07 08:53:30 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/py4j-0.10.9.2.jar to class loader\n",
      "25/11/07 08:53:30 INFO Executor: Fetching spark://fad0f522f137:37383/jars/commons-net-3.1.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:30 INFO Utils: Fetching spark://fad0f522f137:37383/jars/commons-net-3.1.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp7020007087720277594.tmp\n",
      "25/11/07 08:53:30 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/commons-net-3.1.jar to class loader\n",
      "25/11/07 08:53:30 INFO Executor: Fetching spark://fad0f522f137:37383/jars/spark-kvstore_2.12-3.2.0.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:30 INFO Utils: Fetching spark://fad0f522f137:37383/jars/spark-kvstore_2.12-3.2.0.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp4521797215684661026.tmp\n",
      "25/11/07 08:53:30 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/spark-kvstore_2.12-3.2.0.jar to class loader\n",
      "25/11/07 08:53:30 INFO Executor: Fetching spark://fad0f522f137:37383/jars/commons-text-1.6.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:30 INFO Utils: Fetching spark://fad0f522f137:37383/jars/commons-text-1.6.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp8576641514199440394.tmp\n",
      "25/11/07 08:53:30 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/commons-text-1.6.jar to class loader\n",
      "25/11/07 08:53:30 INFO Executor: Fetching spark://fad0f522f137:37383/jars/spark-tags_2.12-3.2.0.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:30 INFO Utils: Fetching spark://fad0f522f137:37383/jars/spark-tags_2.12-3.2.0.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp1904599794759578303.tmp\n",
      "25/11/07 08:53:30 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/spark-tags_2.12-3.2.0.jar to class loader\n",
      "25/11/07 08:53:30 INFO Executor: Fetching spark://fad0f522f137:37383/jars/htrace-core4-4.1.0-incubating.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:30 INFO Utils: Fetching spark://fad0f522f137:37383/jars/htrace-core4-4.1.0-incubating.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp2440017867671906337.tmp\n",
      "25/11/07 08:53:30 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/htrace-core4-4.1.0-incubating.jar to class loader\n",
      "25/11/07 08:53:30 INFO Executor: Fetching spark://fad0f522f137:37383/jars/jersey-container-servlet-core-2.34.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:30 INFO Utils: Fetching spark://fad0f522f137:37383/jars/jersey-container-servlet-core-2.34.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp5260592064708326786.tmp\n",
      "25/11/07 08:53:30 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/jersey-container-servlet-core-2.34.jar to class loader\n",
      "25/11/07 08:53:30 INFO Executor: Fetching spark://fad0f522f137:37383/jars/arrow-vector-2.0.0.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:30 INFO Utils: Fetching spark://fad0f522f137:37383/jars/arrow-vector-2.0.0.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp8844065432847367036.tmp\n",
      "25/11/07 08:53:30 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/arrow-vector-2.0.0.jar to class loader\n",
      "25/11/07 08:53:30 INFO Executor: Fetching spark://fad0f522f137:37383/jars/javassist-3.21.0-GA.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:30 INFO Utils: Fetching spark://fad0f522f137:37383/jars/javassist-3.21.0-GA.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp2964339616462676915.tmp\n",
      "25/11/07 08:53:30 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/javassist-3.21.0-GA.jar to class loader\n",
      "25/11/07 08:53:30 INFO Executor: Fetching spark://fad0f522f137:37383/jars/spark-sketch_2.12-3.2.0.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:30 INFO Utils: Fetching spark://fad0f522f137:37383/jars/spark-sketch_2.12-3.2.0.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp966739647068685873.tmp\n",
      "25/11/07 08:53:30 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/spark-sketch_2.12-3.2.0.jar to class loader\n",
      "25/11/07 08:53:30 INFO Executor: Fetching spark://fad0f522f137:37383/jars/ammonite-repl-api_2.12.20-3.0.2.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:30 INFO Utils: Fetching spark://fad0f522f137:37383/jars/ammonite-repl-api_2.12.20-3.0.2.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp5343689686350505964.tmp\n",
      "25/11/07 08:53:30 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/ammonite-repl-api_2.12.20-3.0.2.jar to class loader\n",
      "25/11/07 08:53:30 INFO Executor: Fetching spark://fad0f522f137:37383/jars/spark-network-common_2.12-3.2.0.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:30 INFO Utils: Fetching spark://fad0f522f137:37383/jars/spark-network-common_2.12-3.2.0.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp6949195524810087880.tmp\n",
      "25/11/07 08:53:30 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/spark-network-common_2.12-3.2.0.jar to class loader\n",
      "25/11/07 08:53:30 INFO Executor: Fetching spark://fad0f522f137:37383/jars/jaxb-api-2.2.11.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:30 INFO Utils: Fetching spark://fad0f522f137:37383/jars/jaxb-api-2.2.11.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp140887744697229205.tmp\n",
      "25/11/07 08:53:30 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/jaxb-api-2.2.11.jar to class loader\n",
      "25/11/07 08:53:30 INFO Executor: Fetching spark://fad0f522f137:37383/jars/slf4j-log4j12-1.7.30.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:30 INFO Utils: Fetching spark://fad0f522f137:37383/jars/slf4j-log4j12-1.7.30.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp2065091285224832451.tmp\n",
      "25/11/07 08:53:30 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/slf4j-log4j12-1.7.30.jar to class loader\n",
      "25/11/07 08:53:30 INFO Executor: Fetching spark://fad0f522f137:37383/jars/arrow-format-2.0.0.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:30 INFO Utils: Fetching spark://fad0f522f137:37383/jars/arrow-format-2.0.0.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp3733222463870314234.tmp\n",
      "25/11/07 08:53:30 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/arrow-format-2.0.0.jar to class loader\n",
      "25/11/07 08:53:30 INFO Executor: Fetching spark://fad0f522f137:37383/jars/orc-shims-1.6.11.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:30 INFO Utils: Fetching spark://fad0f522f137:37383/jars/orc-shims-1.6.11.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp6801873304766904313.tmp\n",
      "25/11/07 08:53:30 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/orc-shims-1.6.11.jar to class loader\n",
      "25/11/07 08:53:30 INFO Executor: Fetching spark://fad0f522f137:37383/jars/parquet-encoding-1.12.1.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:30 INFO Utils: Fetching spark://fad0f522f137:37383/jars/parquet-encoding-1.12.1.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp5701062125582665537.tmp\n",
      "25/11/07 08:53:31 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/parquet-encoding-1.12.1.jar to class loader\n",
      "25/11/07 08:53:31 INFO Executor: Fetching spark://fad0f522f137:37383/jars/lz4-java-1.7.1.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:31 INFO Utils: Fetching spark://fad0f522f137:37383/jars/lz4-java-1.7.1.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp265165780482325505.tmp\n",
      "25/11/07 08:53:31 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/lz4-java-1.7.1.jar to class loader\n",
      "25/11/07 08:53:31 INFO Executor: Fetching spark://fad0f522f137:37383/jars/arrow-memory-netty-2.0.0.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:31 INFO Utils: Fetching spark://fad0f522f137:37383/jars/arrow-memory-netty-2.0.0.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp1911295548178029744.tmp\n",
      "25/11/07 08:53:31 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/arrow-memory-netty-2.0.0.jar to class loader\n",
      "25/11/07 08:53:31 INFO Executor: Fetching spark://fad0f522f137:37383/jars/metrics-jvm-4.2.0.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:31 INFO Utils: Fetching spark://fad0f522f137:37383/jars/metrics-jvm-4.2.0.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp6600931048955051791.tmp\n",
      "25/11/07 08:53:31 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/metrics-jvm-4.2.0.jar to class loader\n",
      "25/11/07 08:53:31 INFO Executor: Fetching spark://fad0f522f137:37383/jars/RoaringBitmap-0.9.0.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:31 INFO Utils: Fetching spark://fad0f522f137:37383/jars/RoaringBitmap-0.9.0.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp4561275763863775076.tmp\n",
      "25/11/07 08:53:31 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/RoaringBitmap-0.9.0.jar to class loader\n",
      "25/11/07 08:53:31 INFO Executor: Fetching spark://fad0f522f137:37383/jars/orc-core-1.6.11.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:31 INFO Utils: Fetching spark://fad0f522f137:37383/jars/orc-core-1.6.11.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp561822905537270975.tmp\n",
      "25/11/07 08:53:31 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/orc-core-1.6.11.jar to class loader\n",
      "25/11/07 08:53:31 INFO Executor: Fetching spark://fad0f522f137:37383/jars/hadoop-client-api-3.3.1.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:31 INFO Utils: Fetching spark://fad0f522f137:37383/jars/hadoop-client-api-3.3.1.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp553064579528756420.tmp\n",
      "25/11/07 08:53:31 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/hadoop-client-api-3.3.1.jar to class loader\n",
      "25/11/07 08:53:31 INFO Executor: Fetching spark://fad0f522f137:37383/jars/fansi_2.12-0.5.0.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:31 INFO Utils: Fetching spark://fad0f522f137:37383/jars/fansi_2.12-0.5.0.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp2399867923610801973.tmp\n",
      "25/11/07 08:53:31 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fansi_2.12-0.5.0.jar to class loader\n",
      "25/11/07 08:53:31 INFO Executor: Fetching spark://fad0f522f137:37383/jars/avro-ipc-1.10.2.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:31 INFO Utils: Fetching spark://fad0f522f137:37383/jars/avro-ipc-1.10.2.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp1593719870917604037.tmp\n",
      "25/11/07 08:53:31 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/avro-ipc-1.10.2.jar to class loader\n",
      "25/11/07 08:53:31 INFO Executor: Fetching spark://fad0f522f137:37383/jars/scalaparse_2.12-3.1.1.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:31 INFO Utils: Fetching spark://fad0f522f137:37383/jars/scalaparse_2.12-3.1.1.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp8155301136690784632.tmp\n",
      "25/11/07 08:53:31 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/scalaparse_2.12-3.1.1.jar to class loader\n",
      "25/11/07 08:53:31 INFO Executor: Fetching spark://fad0f522f137:37383/jars/ammonite-util_2.12-3.0.2.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:31 INFO Utils: Fetching spark://fad0f522f137:37383/jars/ammonite-util_2.12-3.0.2.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp2755139396716572121.tmp\n",
      "25/11/07 08:53:31 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/ammonite-util_2.12-3.0.2.jar to class loader\n",
      "25/11/07 08:53:31 INFO Executor: Fetching spark://fad0f522f137:37383/jars/parquet-hadoop-1.12.1.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:31 INFO Utils: Fetching spark://fad0f522f137:37383/jars/parquet-hadoop-1.12.1.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp8995672293456640741.tmp\n",
      "25/11/07 08:53:31 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/parquet-hadoop-1.12.1.jar to class loader\n",
      "25/11/07 08:53:31 INFO Executor: Fetching spark://fad0f522f137:37383/jars/orc-mapreduce-1.6.11.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:31 INFO Utils: Fetching spark://fad0f522f137:37383/jars/orc-mapreduce-1.6.11.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp9180281385197169948.tmp\n",
      "25/11/07 08:53:31 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/orc-mapreduce-1.6.11.jar to class loader\n",
      "25/11/07 08:53:31 INFO Executor: Fetching spark://fad0f522f137:37383/jars/jupyter-api_2.12-0.14.1.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:31 INFO Utils: Fetching spark://fad0f522f137:37383/jars/jupyter-api_2.12-0.14.1.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp3124986689912351639.tmp\n",
      "25/11/07 08:53:31 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/jupyter-api_2.12-0.14.1.jar to class loader\n",
      "25/11/07 08:53:31 INFO Executor: Fetching spark://fad0f522f137:37383/jars/jersey-common-2.34.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:31 INFO Utils: Fetching spark://fad0f522f137:37383/jars/jersey-common-2.34.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp5024528691565519504.tmp\n",
      "25/11/07 08:53:31 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/jersey-common-2.34.jar to class loader\n",
      "25/11/07 08:53:31 INFO Executor: Fetching spark://fad0f522f137:37383/jars/commons-math3-3.4.1.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:31 INFO Utils: Fetching spark://fad0f522f137:37383/jars/commons-math3-3.4.1.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp5150399851842393600.tmp\n",
      "25/11/07 08:53:31 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/commons-math3-3.4.1.jar to class loader\n",
      "25/11/07 08:53:31 INFO Executor: Fetching spark://fad0f522f137:37383/jars/sourcecode_2.12-0.4.3-M5.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:31 INFO Utils: Fetching spark://fad0f522f137:37383/jars/sourcecode_2.12-0.4.3-M5.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp2108154446257730787.tmp\n",
      "25/11/07 08:53:31 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/sourcecode_2.12-0.4.3-M5.jar to class loader\n",
      "25/11/07 08:53:31 INFO Executor: Fetching spark://fad0f522f137:37383/jars/jackson-databind-2.12.3.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:31 INFO Utils: Fetching spark://fad0f522f137:37383/jars/jackson-databind-2.12.3.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp8800640234285279816.tmp\n",
      "25/11/07 08:53:31 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/jackson-databind-2.12.3.jar to class loader\n",
      "25/11/07 08:53:31 INFO Executor: Fetching spark://fad0f522f137:37383/jars/netty-all-4.1.68.Final.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:31 INFO Utils: Fetching spark://fad0f522f137:37383/jars/netty-all-4.1.68.Final.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp2523999129780640207.tmp\n",
      "25/11/07 08:53:31 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/netty-all-4.1.68.Final.jar to class loader\n",
      "25/11/07 08:53:31 INFO Executor: Fetching spark://fad0f522f137:37383/jars/interface-1.0.29-M1.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:31 INFO Utils: Fetching spark://fad0f522f137:37383/jars/interface-1.0.29-M1.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp8380949844873142037.tmp\n",
      "25/11/07 08:53:31 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/interface-1.0.29-M1.jar to class loader\n",
      "25/11/07 08:53:31 INFO Executor: Fetching spark://fad0f522f137:37383/jars/jvm-repr-0.4.0.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:31 INFO Utils: Fetching spark://fad0f522f137:37383/jars/jvm-repr-0.4.0.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp3463025168374011106.tmp\n",
      "25/11/07 08:53:31 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/jvm-repr-0.4.0.jar to class loader\n",
      "25/11/07 08:53:31 INFO Executor: Fetching spark://fad0f522f137:37383/jars/scala-kernel-api_2.12.20-0.14.1.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:31 INFO Utils: Fetching spark://fad0f522f137:37383/jars/scala-kernel-api_2.12.20-0.14.1.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp3668321095552591354.tmp\n",
      "25/11/07 08:53:31 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/scala-kernel-api_2.12.20-0.14.1.jar to class loader\n",
      "25/11/07 08:53:31 INFO Executor: Fetching spark://fad0f522f137:37383/jars/spark-sql_2.12-3.2.0.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:31 INFO Utils: Fetching spark://fad0f522f137:37383/jars/spark-sql_2.12-3.2.0.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp1326994199284712824.tmp\n",
      "25/11/07 08:53:31 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/spark-sql_2.12-3.2.0.jar to class loader\n",
      "25/11/07 08:53:31 INFO Executor: Fetching spark://fad0f522f137:37383/jars/parquet-common-1.12.1.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:31 INFO Utils: Fetching spark://fad0f522f137:37383/jars/parquet-common-1.12.1.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp5779242107290452366.tmp\n",
      "25/11/07 08:53:31 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/parquet-common-1.12.1.jar to class loader\n",
      "25/11/07 08:53:31 INFO Executor: Fetching spark://fad0f522f137:37383/jars/ammonite-compiler_2.12.20-3.0.2.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:31 INFO Utils: Fetching spark://fad0f522f137:37383/jars/ammonite-compiler_2.12.20-3.0.2.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp5396847597149744071.tmp\n",
      "25/11/07 08:53:31 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/ammonite-compiler_2.12.20-3.0.2.jar to class loader\n",
      "25/11/07 08:53:31 INFO Executor: Fetching spark://fad0f522f137:37383/jars/jackson-core-2.12.3.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:31 INFO Utils: Fetching spark://fad0f522f137:37383/jars/jackson-core-2.12.3.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp5121025321310917000.tmp\n",
      "25/11/07 08:53:31 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/jackson-core-2.12.3.jar to class loader\n",
      "25/11/07 08:53:31 INFO Executor: Fetching spark://fad0f522f137:37383/jars/jersey-container-servlet-2.34.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:31 INFO Utils: Fetching spark://fad0f522f137:37383/jars/jersey-container-servlet-2.34.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp7441825241788636870.tmp\n",
      "25/11/07 08:53:31 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/jersey-container-servlet-2.34.jar to class loader\n",
      "25/11/07 08:53:31 INFO Executor: Fetching spark://fad0f522f137:37383/jars/parquet-column-1.12.1.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:31 INFO Utils: Fetching spark://fad0f522f137:37383/jars/parquet-column-1.12.1.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp1406246041641871051.tmp\n",
      "25/11/07 08:53:32 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/parquet-column-1.12.1.jar to class loader\n",
      "25/11/07 08:53:32 INFO Executor: Fetching spark://fad0f522f137:37383/jars/spark-launcher_2.12-3.2.0.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:32 INFO Utils: Fetching spark://fad0f522f137:37383/jars/spark-launcher_2.12-3.2.0.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp4347323501214302274.tmp\n",
      "25/11/07 08:53:32 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/spark-launcher_2.12-3.2.0.jar to class loader\n",
      "25/11/07 08:53:32 INFO Executor: Fetching spark://fad0f522f137:37383/jars/pyrolite-4.30.jar with timestamp 1762505606055\n",
      "25/11/07 08:53:32 INFO Utils: Fetching spark://fad0f522f137:37383/jars/pyrolite-4.30.jar to /tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/fetchFileTemp9062844003808546239.tmp\n",
      "25/11/07 08:53:32 INFO Executor: Adding file:/tmp/spark-83dcdeb4-f138-449a-b4b8-86cd46277893/userFiles-ffeaf498-022d-4898-893f-f860b29d66a4/pyrolite-4.30.jar to class loader\n",
      "25/11/07 08:53:32 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34827.\n",
      "25/11/07 08:53:32 INFO NettyBlockTransferService: Server created on fad0f522f137:34827\n",
      "25/11/07 08:53:32 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\n",
      "25/11/07 08:53:32 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, fad0f522f137, 34827, None)\n",
      "25/11/07 08:53:32 INFO BlockManagerMasterEndpoint: Registering block manager fad0f522f137:34827 with 366.3 MiB RAM, BlockManagerId(driver, fad0f522f137, 34827, None)\n",
      "25/11/07 08:53:32 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, fad0f522f137, 34827, None)\n",
      "25/11/07 08:53:32 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, fad0f522f137, 34827, None)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a target=\"_blank\" href=\"http://fad0f522f137:4040\">Spark UI</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql._\u001b[39m\n",
       "\u001b[36mspark\u001b[39m: \u001b[32mSparkSession\u001b[39m = org.apache.spark.sql.SparkSession@11709d30\n",
       "\u001b[32mimport \u001b[39m\u001b[36mspark.implicits._\u001b[39m"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql._\n",
    "\n",
    "val spark = {\n",
    "  NotebookSparkSession.builder()\n",
    "    .master(\"local[*]\")\n",
    "    .getOrCreate()\n",
    "}\n",
    "\n",
    "//Set logger level to Warn\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "import spark.implicits._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e191c7c5-f7ba-4615-9aab-0d9a5bb015d3",
   "metadata": {},
   "source": [
    "Let's define the Case class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e38e9196-4be0-4139-b919-339ae269a1b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mclass\u001b[39m \u001b[36mMovie\u001b[39m"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case class Movie(\n",
    "  movieId: Int,\n",
    "  title: String,\n",
    "  genres: String\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1760d8e0-4ac6-4a61-aa85-a9547374f66b",
   "metadata": {},
   "source": [
    "Create a DataSet using the above Case class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31b8b93c-1e4d-4ebe-bf10-5a47329cfe7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------+--------------------+\n",
      "|movieId|           title|              genres|\n",
      "+-------+----------------+--------------------+\n",
      "|      1|Toy Story (1995)|Adventure|Animati...|\n",
      "|      2|  Jumanji (1995)|Adventure|Childre...|\n",
      "+-------+----------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mmoviesDS\u001b[39m: \u001b[32mDataset\u001b[39m[\u001b[32mMovie\u001b[39m] = [movieId: int, title: string ... 1 more field]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Read CSV and convert to Dataset\n",
    "val moviesDS = spark.read\n",
    "  .option(\"header\", \"true\")\n",
    "  .option(\"inferSchema\", \"true\")\n",
    "  .csv(\"ml-latest-small/movies.csv\")\n",
    "  .as[Movie]\n",
    "\n",
    "// Example queries\n",
    "moviesDS.show(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ee03cc-eb53-443e-bfcc-8cd49df36450",
   "metadata": {},
   "source": [
    "**Key Points:**\n",
    "\n",
    "- Case classes must be serializable\n",
    "- All fields should have Spark-compatible types\n",
    "- The `.as[T]` method performs the conversion from DataFrame to Dataset\n",
    "\n",
    "##### Understanding Encoders\n",
    "\n",
    "Encoders are a critical component of the Dataset API. They provide:\n",
    "\n",
    "1. <span>Efficient Serialisation</span>{:gtxt}: Convert JVM objects to Spark's internal Tungsten binary format\n",
    "2. <span>Schema Generation</span>{:gtxt}: Automatically infer schema from case class structure\n",
    "3. <span>Code Generation</span>{:gtxt}: Enable whole-stage code generation for better performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4da7331-736d-4109-9078-3272f6c763cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.Dataset\u001b[39m\n",
       "\u001b[36mintDS\u001b[39m: \u001b[32mDataset\u001b[39m[\u001b[32mInt\u001b[39m] = [value: int]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.Dataset\n",
    "// for primitive types\n",
    "val intDS : Dataset[Int] = Seq(1,2,3).toDS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1773bb4a-9bea-4d3e-9f93-3b3843fd9979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mtupleDS\u001b[39m: \u001b[32mDataset\u001b[39m[(\u001b[32mString\u001b[39m, \u001b[32mInt\u001b[39m)] = [_1: string, _2: int]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val tupleDS: Dataset[(String, Int)] = Seq((\"a\",1), (\"b\", 2)).toDS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59f1245-acdd-4fce-9fee-86a6432caad3",
   "metadata": {},
   "source": [
    "Using Case classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a694367-04d2-4b60-878a-769345a9fa7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mclass\u001b[39m \u001b[36mDog\u001b[39m\n",
       "\u001b[36mdogsDS\u001b[39m: \u001b[32mDataset\u001b[39m[\u001b[32mDog\u001b[39m] = [name: string, age: int]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case class Dog(name: String, age: Int)\n",
    "\n",
    "val dogsDS: Dataset[Dog] = Seq(Dog(\"Liela\",3), Dog(\"Tommy\", 5)).toDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3766010a-06c5-4ae6-a31d-a531e626100f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dogsDS.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7537a3cb-e15e-4b61-8c87-1e95078fe17d",
   "metadata": {},
   "source": [
    "## Dataset Transformations\n",
    "\n",
    "### map Transformation\n",
    "\n",
    "The `map` transformation applies a function to each element in the Dataset, producing a new Dataset with transformed elements. It's a **narrow transformation** (no shuffle required) and maintains a **one-to-one relationship** between input and output elements.\n",
    "\n",
    "```scala\n",
    "def map[U](func: T => U)(implicit encoder: Encoder[U]): Dataset[U]\n",
    "```\n",
    "`f`: function\n",
    "\n",
    "For example, to extract the movie title:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcca7fcf-cae1-4a04-8e2d-a888c6f00f04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+\n",
      "|value                  |\n",
      "+-----------------------+\n",
      "|Toy Story (1995)       |\n",
      "|Jumanji (1995)         |\n",
      "|Grumpier Old Men (1995)|\n",
      "+-----------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "moviesDS.map(m => m.title).show(3, truncate=false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17b8ccd1-3023-42eb-9a08-422c0cec7217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mextractMovieInfoFun\u001b[39m\n",
       "\u001b[36mres9_1\u001b[39m: \u001b[32mDataset\u001b[39m[(\u001b[32mString\u001b[39m, \u001b[32mString\u001b[39m)] = [_1: string, _2: string]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extractMovieInfoFun(movie: Movie): (String, String) = (movie.title, movie.genres)\n",
    "moviesDS.map(extractMovieInfoFun)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a0be87-8108-411c-8644-74cb73b4d59f",
   "metadata": {},
   "source": [
    "As shown above, you can create a function.\n",
    "\n",
    "Or you can create a anonymous function as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79e74d90-b018-4205-bc02-46a5e9b84be8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mextractMovieInfoAnonymousFun\u001b[39m: \u001b[32mMovie\u001b[39m => (\u001b[32mString\u001b[39m, \u001b[32mString\u001b[39m) = ammonite.$sess.cmd10$Helper$$Lambda$7549/1874751541@63bb7cc7\n",
       "\u001b[36mres10_1\u001b[39m: \u001b[32mDataset\u001b[39m[(\u001b[32mString\u001b[39m, \u001b[32mString\u001b[39m)] = [_1: string, _2: string]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val extractMovieInfoAnonymousFun: Movie => (String, String) = movie => (movie.title, movie.genres)\n",
    "moviesDS.map(extractMovieInfoAnonymousFun)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0def72-c627-4c7f-8f36-bb9565b81231",
   "metadata": {},
   "source": [
    "Above can be directly written in the `map` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e19f5ee-9114-455d-8925-67b61e3f3f10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mres11\u001b[39m: \u001b[32mDataset\u001b[39m[(\u001b[32mString\u001b[39m, \u001b[32mString\u001b[39m)] = [_1: string, _2: string]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moviesDS.map(movie => (movie.title, movie.genres))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34648bf6-2f59-488a-ad79-0b1fbe03daf2",
   "metadata": {},
   "source": [
    "### flatMap Transformation\n",
    "\n",
    "The `flatMap` transformation applies a function to each element and **flattens** the results. Each input element can produce **zero, one, or multiple output elements**. This is essential for transformations like tokenization, exploding nested structures, or filtering with expansion.\n",
    "\n",
    "```scala\n",
    "def flatMap[U](func: T => TraversableOnce[U])(implicit encoder: Encoder[U]): Dataset[U]\n",
    "```\n",
    "\n",
    "Translation: Given a function that transforms each element of type `T` into a collection of type `U`, flatten all collections into a single Dataset of type `U`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2180cc3d-d4d3-4c6f-85c0-08b5a914a974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mclass\u001b[39m \u001b[36mMovieGenres\u001b[39m\n",
       "\u001b[36mgenres\u001b[39m: \u001b[32mDataset\u001b[39m[\u001b[32mMovieGenres\u001b[39m] = [id: int, genres: string]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case class MovieGenres (id: Int, genres: String)\n",
    "val genres = moviesDS.map { movie =>\n",
    "    MovieGenres(movie.movieId, movie.genres)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e57b484-cab5-45d8-aee8-195bd4e50b0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------------------------------+\n",
      "|id |genres                                     |\n",
      "+---+-------------------------------------------+\n",
      "|1  |Adventure|Animation|Children|Comedy|Fantasy|\n",
      "|2  |Adventure|Children|Fantasy                 |\n",
      "|3  |Comedy|Romance                             |\n",
      "+---+-------------------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "genres.show(3, truncate=false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f01f8785-bc73-4815-b09c-68d69541d1b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|    value|\n",
      "+---------+\n",
      "|Adventure|\n",
      "|Animation|\n",
      "| Children|\n",
      "|   Comedy|\n",
      "|  Fantasy|\n",
      "|Adventure|\n",
      "| Children|\n",
      "|  Fantasy|\n",
      "|   Comedy|\n",
      "|  Romance|\n",
      "|   Comedy|\n",
      "|    Drama|\n",
      "|  Romance|\n",
      "|   Comedy|\n",
      "|   Action|\n",
      "|    Crime|\n",
      "| Thriller|\n",
      "|   Comedy|\n",
      "|  Romance|\n",
      "|Adventure|\n",
      "+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mgenresDS\u001b[39m: \u001b[32mDataset\u001b[39m[\u001b[32mString\u001b[39m] = [value: string]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val genresDS = genres.flatMap(m => m.genres.split(\"\\\\|\"))\n",
    "genresDS.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f081f24b-cfe3-400a-ab9b-8d328696b68c",
   "metadata": {},
   "source": [
    "> The `split()` method takes a *regex pattern, and `|` is a special character in regex meaning \"OR\"*{:rtxt}. So `split(\"|\")` doesn't work as expected. *Instead, use `split(\"\\\\|\")` for split*{:gtxt}.\n",
    "{:.yellow}\n",
    "\n",
    "Complex Example: Nested Structure Explosion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6273568d-76a9-4e65-b05c-00226b8340ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "case class Sentence(id: Int, words: Seq[String], occurrences: Seq[Int])\n",
    "\n",
    "object Sentence {\n",
    "  // Create Sentence from string format \"1: Hello, how are you?\"\n",
    "  def fromString(input: String): Sentence = {\n",
    "    val parts = input.split(\":\", 2) // Split into ID and text\n",
    "    val id = parts(0).trim.toInt\n",
    "    val text = parts(1).trim\n",
    "    \n",
    "    // Extract words\n",
    "    val words = text.split(\"\\\\s+\").toSeq\n",
    "    \n",
    "    // Count occurrences of each word\n",
    "    val wordCounts = words.groupBy(identity).view.mapValues(_.size).toMap\n",
    "    val occurrences = words.map(word => wordCounts(word))\n",
    "    \n",
    "    Sentence(id, words, occurrences)\n",
    "  }\n",
    "  \n",
    "  // Create multiple Sentences from a list of strings\n",
    "  def fromStrings(inputs: Seq[String]): Seq[Sentence] = {\n",
    "    inputs.map(fromString)\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15640cc-d3f6-4b5b-86b2-5d3588c565eb",
   "metadata": {},
   "source": [
    "[^1]: Chambers, B., Zaharia, M., 2018. Spark: The Definitive Guide. Ch. 11: \"Datasets\"\n",
    "\n",
    "[^2]: Holden Karau, Rachel Warren., 2017. High Performance Spark: Best Practices for Scaling and Optimizing Apache Spark. Ch. 3: \"DataFrames, Datasets, and Spark SQL\"\n",
    "\n",
    "[^3]: Chambers, B., Zaharia, M., 2018. Spark: The Definitive Guide. Ch. 13: \"Advanced RDDs\"\n",
    "\n",
    "[^4]: Holden Karau, Rachel Warren., 2017. High Performance Spark: Best Practices for Scaling and Optimizing Apache Spark. Ch. 4: \"Joins (SQL and Core)\"\n",
    "\n",
    "[^5]: Holden Karau, Rachel Warren., 2017. High Performance Spark: Best Practices for Scaling and Optimizing Apache Spark. Ch. 6: \"Working with Key/Value Data\"\n",
    "\n",
    "[^6]: Ryza, Sandy, Laserson, Uri, Owen, Sean, Wills, Josh., 2017. Advanced Analytics with Spark, 2nd Edition. Ch. 2: \"Introduction to Data Analysis with Scala and Spark\"\n",
    "\n",
    "[^7]: [Apache Spark Dataset API Documentation](https://spark.apache.org/docs/2.4.8/api/scala/index.html#org.apache.spark.sql.Dataset) - Scala 2.x API\n",
    "\n",
    "{:gtxt: .message color=\"green\"}\n",
    "{:ytxt: .message color=\"yellow\"}\n",
    "{:rtxt: .message color=\"red\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0664f90-f90f-43c2-ae13-0ce976ab2bfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mres15\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"version 2.12.20\"\u001b[39m"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scala.util.Properties.versionString\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2f6c6ce-35ca-43c2-b34c-fb17fa54ec83",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a364aa93-80a7-4f5f-942f-aa2f4039a190",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala 2.12",
   "language": "scala",
   "name": "scala212"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
