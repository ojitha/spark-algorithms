{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1363d630-f517-4d8c-bb11-b4d055aec633",
   "metadata": {},
   "source": [
    "---\n",
    "layout: post\n",
    "title:  Spark Dataset APIs\n",
    "date:   2025-11-07\n",
    "categories: [Spark, Scala]\n",
    "mermaid: true\n",
    "maths: true\n",
    "typora-root-url: /Users/ojitha/GitHub/ojitha.github.io\n",
    "typora-copy-images-to: ../../blog/assets/images/${filename}\n",
    "---\n",
    "\n",
    "<style>\n",
    "/* Styles for the two-column layout */\n",
    ".image-text-container {\n",
    "    display: flex; /* Enables flexbox */\n",
    "    flex-wrap: wrap; /* Allows columns to stack on small screens */\n",
    "    gap: 20px; /* Space between the image and text */\n",
    "    align-items: center; /* Vertically centers content in columns */\n",
    "    margin-bottom: 20px; /* Space below this section */\n",
    "}\n",
    "\n",
    ".image-column {\n",
    "    flex: 1; /* Allows this column to grow */\n",
    "    min-width: 250px; /* Minimum width for the image column before stacking */\n",
    "    max-width: 40%; /* Maximum width for the image column to not take up too much space initially */\n",
    "    box-sizing: border-box; /* Include padding/border in element's total width/height */\n",
    "}\n",
    "\n",
    ".text-column {\n",
    "    flex: 2; /* Allows this column to grow more (e.g., twice as much as image-column) */\n",
    "    min-width: 300px; /* Minimum width for the text column before stacking */\n",
    "    box-sizing: border-box;\n",
    "}\n",
    "\n",
    "</style>\n",
    "\n",
    "<div class=\"image-text-container\">\n",
    "    <div class=\"image-column\">\n",
    "        <img src=\"https://raw.githubusercontent.com/ojitha/blog/master/assets/images/2025-10027-Scala-2-Collections/scala-collections-illustration.svg\" alt=\"Scala Functors\" width=\"150\" height=\"150\">\n",
    "    </div>\n",
    "    <div class=\"text-column\">\n",
    "<p>TBC</p>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "<!--more-->\n",
    "\n",
    "------\n",
    "\n",
    "* TOC\n",
    "{:toc}\n",
    "------\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619071eb-808f-4e4e-b45f-617bc367132f",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "### What are Datasets?\n",
    "\n",
    "Apache Spark Datasets are the foundational type in Spark's Structured APIs, providing a **type-safe**, distributed collection of strongly typed JVM objects. While DataFrames are Datasets of type `Row`, Datasets allow you to define custom domain-specific objects that each row will consist of, combining the benefits of RDDs (type safety, custom objects) with the optimizations of DataFrames (Catalyst optimizer, Tungsten execution).\n",
    "\n",
    "**Key Characteristics:**\n",
    "\n",
    "1. **Type Safety**: Compile-time type checking prevents runtime type errors\n",
    "2. **Encoders**: Special serialization mechanism that maps domain-specific types to Spark's internal binary format\n",
    "3. **Catalyst Optimization**: Benefits from Spark SQL's query optimizer\n",
    "4. **JVM Language Feature**: Available only in Scala and Java (not Python or R)\n",
    "5. **Functional API**: Supports functional transformations like `map`, `filter`, `flatMap`\n",
    "\n",
    "**Dataset[T]**: A distributed collection of data elements of type `T`, where `T` is a domain-specific class (case class in Scala, JavaBean in Java) that Spark can encode and optimize.\n",
    "\n",
    "$$\n",
    "\\text{Dataset}[T] = \\{t_1, t_2, \\ldots, t_n\\} \\text{ where } t_i \\in T\n",
    "$$\n",
    "\n",
    "Translation: A Dataset of type T is a collection of n elements, where each element belongs to type T.\n",
    "\n",
    "**Encoder[T]**: A mechanism that converts between JVM objects of type `T` and Spark SQL's internal binary format (InternalRow).\n",
    "\n",
    "$$\n",
    "\\text{Encoder}[T]: T \\leftrightarrow \\text{InternalRow}\n",
    "$$\n",
    "\n",
    "Translation: An Encoder for type T provides bidirectional conversion between objects of type T and Spark's internal row representation.\n",
    "\n",
    "### Mathematical Foundations\n",
    "\n",
    "Datasets embody key functional programming concepts:\n",
    "\n",
    "1. **Functor Laws** (for `map`):\n",
    "    - Identity: `ds.map(x => x) = ds`\n",
    "    - Composition: `ds.map(f).map(g) = ds.map(x => g(f(x)))`\n",
    "\n",
    "2. **Monad Laws** (for `flatMap`):\n",
    "    - Left identity: `Dataset(x).flatMap(f) = f(x)`\n",
    "    - Right identity: `ds.flatMap(x => Dataset(x)) = ds`\n",
    "    - Associativity: `ds.flatMap(f).flatMap(g) = ds.flatMap(x => f(x).flatMap(g))`\n",
    "\n",
    "### Dataset Movie Lens\n",
    "\n",
    "Let's examine the MovieLens dataset: [recommended for education and development](https://grouplens.org/datasets/movielens/){:target=\"_blank\"} for simplicity.\n",
    "\n",
    "```mermaid\n",
    "---\n",
    "config:\n",
    "  look: neo\n",
    "  theme: default\n",
    "---\n",
    "erDiagram\n",
    "    Movies ||--o{ Ratings : \"receives\"\n",
    "    Movies ||--o{ Tags : \"has\"\n",
    "    Movies ||--|| Links : \"references\"\n",
    "    \n",
    "    Movies {\n",
    "        int movieId PK \"Primary Key\"\n",
    "        string title \"Movie title with year\"\n",
    "        string genres \"Pipe-separated genres\"\n",
    "    }\n",
    "    \n",
    "    Ratings {\n",
    "        int userId FK \"Foreign Key to User\"\n",
    "        int movieId FK \"Foreign Key to Movie\"\n",
    "        float rating \"Rating value (0.5-5.0)\"\n",
    "        long timestamp \"Unix timestamp\"\n",
    "    }\n",
    "    \n",
    "    Tags {\n",
    "        int userId FK \"Foreign Key to User\"\n",
    "        int movieId FK \"Foreign Key to Movie\"\n",
    "        string tag \"User-generated tag\"\n",
    "        long timestamp \"Unix timestamp\"\n",
    "    }\n",
    "    \n",
    "    Links {\n",
    "        int movieId PK \"Primary Key\"\n",
    "        int movieId FK \"Foreign Key to Movie\"\n",
    "        string imdbId \"IMDB identifier\"\n",
    "        string tmdbId \"TMDB identifier\"\n",
    "    }\n",
    "```\n",
    "\n",
    "#### Entities and Attributes\n",
    "\n",
    "1.  **Movies** (9,742 movies)\n",
    "    -   `movieId` (Primary Key)\n",
    "    -   `title` (includes release year)\n",
    "    -   `genres` (pipe-separated list)\n",
    "2.  **Ratings** (100,836 ratings)\n",
    "    -   `userId` (Foreign Key)\n",
    "    -   `movieId` (Foreign Key)\n",
    "    -   `rating` (0.5 to 5.0 stars)\n",
    "    -   `timestamp` (Unix timestamp)\n",
    "3.  **Tags** (3,683 tags)\n",
    "    -   `userId` (Foreign Key)\n",
    "    -   `movieId` (Foreign Key)\n",
    "    -   `tag` (user-generated metadata)\n",
    "    -   `timestamp` (Unix timestamp)\n",
    "4.  **Links** (9,742 links)\n",
    "    -   `movieId` (Primary Key & Foreign Key)\n",
    "    -   `imdbId` (IMDB identifier)\n",
    "    -   `tmdbId` (The Movie Database identifier)\n",
    "\n",
    "#### Relationships\n",
    "\n",
    "-   **Movies ‚Üî Ratings**: One-to-Many (a movie can have multiple ratings)\n",
    "-   **Movies ‚Üî Tags**: One-to-Many (a movie can have multiple tags)\n",
    "-   **Movies ‚Üî Links**: One-to-One (each movie has one set of external links)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b84bbeb-778c-49de-88c8-82a8ec31f328",
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.logging.log4j.{LogManager, Level}\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.logging.log4j.core.config.Configurator\u001b[39m"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Configure Coursier to fetch doc JARs\n",
    "interp.repositories() ++= Seq(\n",
    "coursierapi.MavenRepository.of(\"https://repo1.maven.org/maven2\")\n",
    ")\n",
    "\n",
    "// Enable compiler to use Java classpath (REMOVED the invalid doc.value line)\n",
    "interp.configureCompiler(c => {\n",
    "c.settings.usejavacp.value = true\n",
    "})\n",
    "\n",
    "// Import Spark\n",
    "import $ivy.`org.apache.spark::spark-sql:3.3.1` \n",
    "import org.apache.logging.log4j.{LogManager, Level}\n",
    "import org.apache.logging.log4j.core.config.Configurator\n",
    "\n",
    "// Set log levels BEFORE creating SparkSession\n",
    "Configurator.setRootLevel(Level.WARN)\n",
    "Configurator.setLevel(\"org.apache.spark\", Level.WARN)\n",
    "Configurator.setLevel(\"org.apache.spark.executor.Executor\", Level.WARN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d061574b-1b6c-4d45-a99c-d3a88690f56c",
   "metadata": {
    "tags": [
     "remove_output"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Loading <code>spark-stubs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Getting spark JARs\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Creating SparkSession\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SLF4J: Class path contains multiple SLF4J bindings.\n",
      "SLF4J: Found binding in [jar:file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/logging/log4j/log4j-slf4j-impl/2.17.2/log4j-slf4j-impl-2.17.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: Found binding in [jar:file:/home/jovyan/.cache/coursier/v1/https/repo1.maven.org/maven2/org/slf4j/slf4j-log4j12/1.7.30/slf4j-log4j12-1.7.30.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
      "SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:49:28.929 [scala-interpreter-1] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a target=\"_blank\" href=\"http://f39ce8c5569c:4040\">Spark UI</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql._\u001b[39m\n",
       "\u001b[36mspark\u001b[39m: \u001b[32mSparkSession\u001b[39m = org.apache.spark.sql.SparkSession@2645c652"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql._\n",
    "\n",
    "val spark = {\n",
    "  NotebookSparkSession.builder()\n",
    "    .master(\"local[*]\")\n",
    "    .getOrCreate()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcda9742-887e-4abd-8af6-df4ceeaa9d72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mspark.implicits._\u001b[39m"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spark.implicits._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e191c7c5-f7ba-4615-9aab-0d9a5bb015d3",
   "metadata": {},
   "source": [
    "Let's define the Case class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e38e9196-4be0-4139-b919-339ae269a1b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mclass\u001b[39m \u001b[36mMovie\u001b[39m"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case class Movie(\n",
    "  movieId: Int,\n",
    "  title: String,\n",
    "  genres: String\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1760d8e0-4ac6-4a61-aa85-a9547374f66b",
   "metadata": {},
   "source": [
    "Create a DataSet using the above Case class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31b8b93c-1e4d-4ebe-bf10-5a47329cfe7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------+--------------------+\n",
      "|movieId|           title|              genres|\n",
      "+-------+----------------+--------------------+\n",
      "|      1|Toy Story (1995)|Adventure|Animati...|\n",
      "|      2|  Jumanji (1995)|Adventure|Childre...|\n",
      "+-------+----------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mmoviesDS\u001b[39m: \u001b[32mDataset\u001b[39m[\u001b[32mMovie\u001b[39m] = [movieId: int, title: string ... 1 more field]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Read CSV and convert to Dataset\n",
    "val moviesDS = spark.read\n",
    "  .option(\"header\", \"true\")\n",
    "  .option(\"inferSchema\", \"true\")\n",
    "  .csv(\"ml-latest-small/movies.csv\")\n",
    "  .as[Movie]\n",
    "\n",
    "// Example queries\n",
    "moviesDS.show(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ee03cc-eb53-443e-bfcc-8cd49df36450",
   "metadata": {},
   "source": [
    "**Key Points:**\n",
    "\n",
    "- Case classes must be serializable\n",
    "- All fields should have Spark-compatible types\n",
    "- The `.as[T]` method performs the conversion from DataFrame to Dataset\n",
    "\n",
    "##### Understanding Encoders\n",
    "\n",
    "Encoders are a critical component of the Dataset API. They provide:\n",
    "\n",
    "1. <span>Efficient Serialisation</span>{:gtxt}: Convert JVM objects to Spark's internal Tungsten binary format\n",
    "2. <span>Schema Generation</span>{:gtxt}: Automatically infer schema from case class structure\n",
    "3. <span>Code Generation</span>{:gtxt}: Enable whole-stage code generation for better performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4da7331-736d-4109-9078-3272f6c763cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.Dataset\u001b[39m\n",
       "\u001b[36mintDS\u001b[39m: \u001b[32mDataset\u001b[39m[\u001b[32mInt\u001b[39m] = [value: int]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.Dataset\n",
    "// for primitive types\n",
    "val intDS : Dataset[Int] = Seq(1,2,3).toDS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1773bb4a-9bea-4d3e-9f93-3b3843fd9979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mtupleDS\u001b[39m: \u001b[32mDataset\u001b[39m[(\u001b[32mString\u001b[39m, \u001b[32mInt\u001b[39m)] = [_1: string, _2: int]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val tupleDS: Dataset[(String, Int)] = Seq((\"a\",1), (\"b\", 2)).toDS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59f1245-acdd-4fce-9fee-86a6432caad3",
   "metadata": {},
   "source": [
    "Using Case classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a694367-04d2-4b60-878a-769345a9fa7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mclass\u001b[39m \u001b[36mDog\u001b[39m\n",
       "\u001b[36mdogsDS\u001b[39m: \u001b[32mDataset\u001b[39m[\u001b[32mDog\u001b[39m] = [name: string, age: int]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case class Dog(name: String, age: Int)\n",
    "\n",
    "val dogsDS: Dataset[Dog] = Seq(Dog(\"Liela\",3), Dog(\"Tommy\", 5)).toDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3766010a-06c5-4ae6-a31d-a531e626100f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+\n",
      "| name|age|\n",
      "+-----+---+\n",
      "|Liela|  3|\n",
      "|Tommy|  5|\n",
      "+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dogsDS.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7537a3cb-e15e-4b61-8c87-1e95078fe17d",
   "metadata": {},
   "source": [
    "## Dataset Transformations\n",
    "\n",
    "### map Transformation\n",
    "\n",
    "The `map` transformation applies a function to each element in the Dataset, producing a new Dataset with transformed elements. It's a **narrow transformation** (no shuffle required) and maintains a **one-to-one relationship** between input and output elements.\n",
    "\n",
    "Signature:\n",
    "\n",
    "```scala\n",
    "def map[U](func: T => U)(implicit encoder: Encoder[U]): Dataset[U]\n",
    "```\n",
    "`f`: function\n",
    "\n",
    "For example, to extract the movie title:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcca7fcf-cae1-4a04-8e2d-a888c6f00f04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+\n",
      "|value                  |\n",
      "+-----------------------+\n",
      "|Toy Story (1995)       |\n",
      "|Jumanji (1995)         |\n",
      "|Grumpier Old Men (1995)|\n",
      "+-----------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "moviesDS.map(m => m.title).show(3, truncate=false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17b8ccd1-3023-42eb-9a08-422c0cec7217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mextractMovieInfoFun\u001b[39m\n",
       "\u001b[36mres11_1\u001b[39m: \u001b[32mDataset\u001b[39m[(\u001b[32mString\u001b[39m, \u001b[32mString\u001b[39m)] = [_1: string, _2: string]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extractMovieInfoFun(movie: Movie): (String, String) = (movie.title, movie.genres)\n",
    "moviesDS.map(extractMovieInfoFun)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a0be87-8108-411c-8644-74cb73b4d59f",
   "metadata": {},
   "source": [
    "As shown above, you can create a function.\n",
    "\n",
    "Or you can create a anonymous function as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79e74d90-b018-4205-bc02-46a5e9b84be8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mextractMovieInfoAnonymousFun\u001b[39m: \u001b[32mMovie\u001b[39m => (\u001b[32mString\u001b[39m, \u001b[32mString\u001b[39m) = ammonite.$sess.cmd12$Helper$$Lambda$6521/992100117@655d1ff7\n",
       "\u001b[36mres12_1\u001b[39m: \u001b[32mDataset\u001b[39m[(\u001b[32mString\u001b[39m, \u001b[32mString\u001b[39m)] = [_1: string, _2: string]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val extractMovieInfoAnonymousFun: Movie => (String, String) = movie => (movie.title, movie.genres)\n",
    "moviesDS.map(extractMovieInfoAnonymousFun)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0def72-c627-4c7f-8f36-bb9565b81231",
   "metadata": {},
   "source": [
    "Above can be directly written in the `map` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e19f5ee-9114-455d-8925-67b61e3f3f10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mres13\u001b[39m: \u001b[32mDataset\u001b[39m[(\u001b[32mString\u001b[39m, \u001b[32mString\u001b[39m)] = [_1: string, _2: string]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moviesDS.map(movie => (movie.title, movie.genres))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34648bf6-2f59-488a-ad79-0b1fbe03daf2",
   "metadata": {},
   "source": [
    "### flatMap Transformation\n",
    "\n",
    "The `flatMap` transformation applies a function to each element and **flattens** the results. Each input element can produce **zero, one, or multiple output elements**. This is essential for transformations like tokenization, exploding nested structures, or filtering with expansion.\n",
    "\n",
    "Signature:\n",
    "\n",
    "```scala\n",
    "def flatMap[U](func: T => TraversableOnce[U])(implicit encoder: Encoder[U]): Dataset[U]\n",
    "```\n",
    "\n",
    "Translation: Given a function that transforms each element of type `T` into a collection of type `U`, flatten all collections into a single Dataset of type `U`.\n",
    "\n",
    "- **Monad Operation**: flatMap enables chaining transformations that produce collections\n",
    "- **One-to-Many Mapping**: Input orders (3) produce output items (6)\n",
    "- Demonstrates nested iteration flattening\n",
    "\n",
    "For a Dataset with $n$ elements, where each element produces $m_i$ results:\n",
    "\n",
    "$$\n",
    "|\\text{flatMap}(ds, f)| = \\sum_{i=1}^{n} m_i\n",
    "$$\n",
    "\n",
    "Translation: The size of the flatMapped Dataset equals the sum of results from each element's transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2180cc3d-d4d3-4c6f-85c0-08b5a914a974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mclass\u001b[39m \u001b[36mMovieGenres\u001b[39m\n",
       "\u001b[36mgenres\u001b[39m: \u001b[32mDataset\u001b[39m[\u001b[32mMovieGenres\u001b[39m] = [id: int, genres: string]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case class MovieGenres (id: Int, genres: String)\n",
    "val genres = moviesDS.map { movie =>\n",
    "    MovieGenres(movie.movieId, movie.genres)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e57b484-cab5-45d8-aee8-195bd4e50b0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------------------------------+\n",
      "|id |genres                                     |\n",
      "+---+-------------------------------------------+\n",
      "|1  |Adventure|Animation|Children|Comedy|Fantasy|\n",
      "|2  |Adventure|Children|Fantasy                 |\n",
      "|3  |Comedy|Romance                             |\n",
      "+---+-------------------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "genres.show(3, truncate=false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f01f8785-bc73-4815-b09c-68d69541d1b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|    value|\n",
      "+---------+\n",
      "|Adventure|\n",
      "|Animation|\n",
      "| Children|\n",
      "|   Comedy|\n",
      "|  Fantasy|\n",
      "+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mgenresDS\u001b[39m: \u001b[32mDataset\u001b[39m[\u001b[32mString\u001b[39m] = [value: string]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val genresDS = genres.flatMap(m => m.genres.split(\"\\\\|\"))\n",
    "genresDS.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f081f24b-cfe3-400a-ab9b-8d328696b68c",
   "metadata": {},
   "source": [
    "> The `split()` method takes a *regex pattern, and `|` is a special character in regex meaning \"OR\"*{:rtxt}. So `split(\"|\")` doesn't work as expected. *Instead, use `split(\"\\\\|\")` for split*{:gtxt}.\n",
    "{:.yellow}\n",
    "\n",
    "Complex Example: Nested Structure Explosion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6273568d-76a9-4e65-b05c-00226b8340ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mclass\u001b[39m \u001b[36mGenreOccurences\u001b[39m\n",
       "defined \u001b[32mobject\u001b[39m \u001b[36mGenreOccurences\u001b[39m"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case class GenreOccurences(id: Int, words: Seq[String], occurrences: Seq[Int])\n",
    "// companion object for the above case class\n",
    "object GenreOccurences {\n",
    "  def fromMovie(movie: Movie): GenreOccurences = {\n",
    "    val id = movie.movieId\n",
    "    val text = movie.genres\n",
    "    \n",
    "    // Extract words\n",
    "    val words = text.split(\"\\\\|\").toSeq\n",
    "    \n",
    "    // Count occurrences of each word\n",
    "    val wordCounts = words.groupBy(identity).mapValues(_.size).toMap\n",
    "    val occurrences = words.map(word => wordCounts(word))\n",
    "    \n",
    "    GenreOccurences(id, words, occurrences)\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff4df117-b608-43c4-ad5f-64acbf253d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mgenreOccurencesDS\u001b[39m: \u001b[32mDataset\u001b[39m[\u001b[32mGenreOccurences\u001b[39m] = [id: int, words: array<string> ... 1 more field]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val genreOccurencesDS: Dataset[GenreOccurences] = moviesDS.map(GenreOccurences.fromMovie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5639d821-ccae-4234-9316-8c87942df837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+---------------+\n",
      "| id|               words|    occurrences|\n",
      "+---+--------------------+---------------+\n",
      "|  1|[Adventure, Anima...|[1, 1, 1, 1, 1]|\n",
      "|  2|[Adventure, Child...|      [1, 1, 1]|\n",
      "|  3|   [Comedy, Romance]|         [1, 1]|\n",
      "+---+--------------------+---------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "genreOccurencesDS.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "56d5f081-fdf0-498c-ad64-ed107ef32f91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+---+\n",
      "| _1|       _2| _3|\n",
      "+---+---------+---+\n",
      "|  1|Adventure|  1|\n",
      "|  1|Animation|  1|\n",
      "|  1| Children|  1|\n",
      "|  1|   Comedy|  1|\n",
      "|  1|  Fantasy|  1|\n",
      "+---+---------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "genreOccurencesDS.flatMap { genreOccurence =>\n",
    "    genreOccurence.words.zip(genreOccurence.occurrences).map { case (word, numOccured) =>\n",
    "        (genreOccurence.id, word, numOccured)\n",
    "        \n",
    "    }\n",
    "}.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb97f69-2eb8-4c3e-a8dc-c1da76f47bd5",
   "metadata": {},
   "source": [
    "Another simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2d4064a5-78a1-4c74-b817-776ffabb30f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mclass\u001b[39m \u001b[36mSentence\u001b[39m"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case class Sentence(id: Int, text: String)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb7e00b-52e8-4ec0-8ff2-919bc466ae8c",
   "metadata": {},
   "source": [
    "Create a sample Dataset[^2]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "36eb3cc4-b1f3-4ab4-baf0-5778e5b56913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36msentences\u001b[39m: \u001b[32mDataset\u001b[39m[\u001b[32mSentence\u001b[39m] = [id: int, text: string]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val sentences = Seq(\n",
    "    Sentence(1, \"Australia is a large continent and a island\"),\n",
    "    Sentence(2, \"Sri Lanka is not a continent but a island\"),\n",
    ").toDS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058b52d7-508c-439a-9665-3fe11f8ff865",
   "metadata": {},
   "source": [
    "if you use map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e9544e27-749f-4f5c-ac79-d2c8350f7803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------+\n",
      "|value                                               |\n",
      "+----------------------------------------------------+\n",
      "|[Australia, is, a, large, continent, and, a, island]|\n",
      "|[Sri, Lanka, is, not, a, continent, but, a, island] |\n",
      "+----------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mwords\u001b[39m: \u001b[32mDataset\u001b[39m[\u001b[32mArray\u001b[39m[\u001b[32mString\u001b[39m]] = [value: array<string>]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val words = sentences.map( s => s.text.split(\"\\\\s+\"))\n",
    "words.show(truncate=false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7a9b3e-4278-4a96-ba5e-cf426871bdec",
   "metadata": {},
   "source": [
    "As shown above, after splitting, the data is stored as an `Array` of `String`s.\n",
    "\n",
    "if you use the `flatmap`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bf13e250-eebe-49ee-b31c-93e6f43eeda1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|value    |\n",
      "+---------+\n",
      "|Australia|\n",
      "|is       |\n",
      "|a        |\n",
      "|large    |\n",
      "|continent|\n",
      "+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mwordsFlat\u001b[39m: \u001b[32mDataset\u001b[39m[\u001b[32mString\u001b[39m] = [value: string]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val wordsFlat = sentences.flatMap( s => s.text.split(\"\\\\s+\"))\n",
    "wordsFlat.show(5, truncate=false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa7e9c5-3377-459a-adf8-d891331fc527",
   "metadata": {},
   "source": [
    "### join Transformation\n",
    "\n",
    "The `join` transformation combines two Datasets based on a join condition (typically equality on one or more columns). This is a **wide transformation** requiring a shuffle to co-locate matching keys. The result is a **DataFrame** (untyped), losing type information.\n",
    "\n",
    "Signature:\n",
    "\n",
    "```scala\n",
    "def join(right: Dataset[_], joinExprs: Column, joinType: String): DataFrame\n",
    "```\n",
    "\n",
    "Translation: Join this Dataset with another Dataset using a join expression and join type, returning a DataFrame.\n",
    "\n",
    "#### Join Types\n",
    "\n",
    "| Join Type             | Description                    | Behavior                                                   |\n",
    "| --------------------- | ------------------------------ | ---------------------------------------------------------- |\n",
    "| `inner`               | Inner join (default)           | Returns only matching rows from both Datasets              |\n",
    "| `left`/`left_outer`   | Left outer join                | Returns all rows from left, nulls for non-matches on right |\n",
    "| `right`/`right_outer` | Right outer join               | Returns all rows from right, nulls for non-matches on left |\n",
    "| `full`/`full_outer`   | Full outer join                | Returns all rows from both, nulls for non-matches          |\n",
    "| `left_semi`           | Left semi join                 | Returns rows from left that have matches in right          |\n",
    "| `left_anti`           | Left anti join                 | Returns rows from left that don't have matches in right    |\n",
    "| `cross`               | Cross join (Cartesian product) | Returns all combinations of rows                           |\n",
    "\n",
    "Tableüìù[^1]: Join Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "388d4a00-a651-44ae-9091-ee762b2eb545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mclass\u001b[39m \u001b[36mRating\u001b[39m"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case class Rating(\n",
    "  userId: Int,\n",
    "  movieId: Int,\n",
    "  rating: Double,\n",
    "  timestamp: Long\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9d0e125b-984e-456f-bc85-e5bbdbe76be1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mratingsDS\u001b[39m: \u001b[32mDataset\u001b[39m[\u001b[32mRating\u001b[39m] = [userId: int, movieId: int ... 2 more fields]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val ratingsDS = spark.read\n",
    "  .option(\"header\", \"true\")\n",
    "  .option(\"inferSchema\", \"true\")\n",
    "  .csv(\"ml-latest-small/ratings.csv\")\n",
    "  .as[Rating]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0809627a-625f-458f-8100-70b6a6a94730",
   "metadata": {},
   "source": [
    "The join is performed on the common `movieId` column that exists in both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4a106b52-57e1-4c6c-85f8-70d4696952a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mmovieRatingsDS\u001b[39m: \u001b[32mDataFrame\u001b[39m = [movieId: int, userId: int ... 4 more fields]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val movieRatingsDS = ratingsDS.join(moviesDS, \"movieId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "73b5d2e9-cc4a-4a96-90ab-e2e2ff784610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------+---------+---------------------------+-------------------------------------------+\n",
      "|movieId|userId|rating|timestamp|title                      |genres                                     |\n",
      "+-------+------+------+---------+---------------------------+-------------------------------------------+\n",
      "|1      |1     |4.0   |964982703|Toy Story (1995)           |Adventure|Animation|Children|Comedy|Fantasy|\n",
      "|3      |1     |4.0   |964981247|Grumpier Old Men (1995)    |Comedy|Romance                             |\n",
      "|6      |1     |4.0   |964982224|Heat (1995)                |Action|Crime|Thriller                      |\n",
      "|47     |1     |5.0   |964983815|Seven (a.k.a. Se7en) (1995)|Mystery|Thriller                           |\n",
      "|50     |1     |5.0   |964982931|Usual Suspects, The (1995) |Crime|Mystery|Thriller                     |\n",
      "+-------+------+------+---------+---------------------------+-------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movieRatingsDS.show(5, truncate=false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3090d1d0-b2ce-4601-baa8-71f167db70f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|movieId|avg(rating)      |\n",
      "+-------+-----------------+\n",
      "|1580   |3.487878787878788|\n",
      "|2366   |3.64             |\n",
      "|3175   |3.58             |\n",
      "|1088   |3.369047619047619|\n",
      "|32460  |4.25             |\n",
      "+-------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mavgRatingsDS\u001b[39m: \u001b[32mDataFrame\u001b[39m = [movieId: int, avg(rating): double]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val avgRatingsDS = ratingsDS.groupBy(\"movieId\").avg(\"rating\")\n",
    "avgRatingsDS.show(5, truncate = false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d95b992-532a-4cf5-babf-a15c96b26cd1",
   "metadata": {},
   "source": [
    "> üíÅüèª‚Äç‚ôÇÔ∏è Important to notice that the join output is a Dataframe(`Dataset[Row]`), not a Dataset.\n",
    "\n",
    "Above `avgRatingsDS` Dataframe can be joined with `moviesDS` Dataset, but the result is Dataframe `Dataset[Row]`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "63ef6448-2b71-4c00-a090-a5da9a6e041f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mavgMovieRatingsDS\u001b[39m: \u001b[32mDataset\u001b[39m[\u001b[32mRow\u001b[39m] = [movieId: int, Title: string ... 1 more field]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val avgMovieRatingsDS =avgRatingsDS.join(moviesDS, \"movieId\")\n",
    "    .select(\"movieId\", \"Title\", \"avg(rating)\")\n",
    "    .orderBy(\"avg(rating)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "99acef9f-6ddc-4c2c-997c-4fa14c487912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------------+-----------+\n",
      "|movieId|Title                  |avg(rating)|\n",
      "+-------+-----------------------+-----------+\n",
      "|138186 |Sorrow (2015)          |0.5        |\n",
      "|5105   |Don't Look Now (1973)  |0.5        |\n",
      "|89386  |Pearl Jam Twenty (2011)|0.5        |\n",
      "|72424  |Derailed (2002)        |0.5        |\n",
      "|134246 |Survivor (2015)        |0.5        |\n",
      "+-------+-----------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "avgMovieRatingsDS.show(5, truncate=false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90723a91-0e3b-40d4-9974-80ba876328eb",
   "metadata": {},
   "source": [
    "### joinWith Transformation\n",
    "\n",
    "The `joinWith` transformation is a **type-safe** alternative to standard join. Unlike `join`, it returns a **Dataset of tuples** `Dataset[(T, U)]`, preserving type information from both Datasets. This is similar to **co-group** operations in RDD terminology.\n",
    "\n",
    "#### Signature\n",
    "\n",
    "```scala\n",
    "def joinWith[U](other: Dataset[U], condition: Column, joinType: String): Dataset[(T, U)]\n",
    "```\n",
    "\n",
    "Translation: Join this Dataset[T] with another Dataset[U] using a condition, returning a Dataset of tuples containing elements from both Datasets (basically end up with two nested Datasets inside of one).\n",
    "\n",
    "#### Key Differences from join\n",
    "\n",
    "| Aspect        | join                | joinWith                  |\n",
    "| ------------- | ------------------- | ------------------------- |\n",
    "| Return Type   | DataFrame (untyped) | Dataset[(T, U)] (typed)   |\n",
    "| Type Safety   | ‚ùå Lost              | ‚úÖ Preserved               |\n",
    "| Column Access | By name (string)    | By object fields          |\n",
    "| Use Case      | SQL-style queries   | Type-safe transformations |\n",
    "\n",
    "Tableüìù[^1]: Key differences\n",
    "\n",
    "#### JoinWith Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "71398c06-cdf5-43bf-a22f-ed44af42dd27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mmovieRatingsDS\u001b[39m: \u001b[32mDataset\u001b[39m[(\u001b[32mMovie\u001b[39m, \u001b[32mRow\u001b[39m)] = [_1: struct<movieId: int, title: string ... 1 more field>, _2: struct<movieId: int, avg(rating): double>]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val movieRatingsDS = moviesDS.joinWith(\n",
    "    avgRatingsDS, moviesDS(\"movieId\") === avgRatingsDS(\"movieId\") )\n",
    "    .orderBy(avgRatingsDS(\"avg(rating)\").desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "98e6f7fd-8616-40dc-a653-759a50ef22be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------+-------------+\n",
      "|_1                                                               |_2           |\n",
      "+-----------------------------------------------------------------+-------------+\n",
      "|{142444, The Editor (2015), Comedy|Horror|Mystery}               |{142444, 5.0}|\n",
      "|{152711, Who Killed Chea Vichea? (2010), Documentary}            |{152711, 5.0}|\n",
      "|{157775, Tenchi Muy√¥! In Love (1996), Animation|Comedy}          |{157775, 5.0}|\n",
      "|{496, What Happened Was... (1994), Comedy|Drama|Romance|Thriller}|{496, 5.0}   |\n",
      "|{8911, Raise Your Voice (2004), Romance}                         |{8911, 5.0}  |\n",
      "+-----------------------------------------------------------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movieRatingsDS.show(5, truncate=false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "02258533-c579-4880-91e2-76823b2c8b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _1: struct (nullable = false)\n",
      " |    |-- movieId: integer (nullable = true)\n",
      " |    |-- title: string (nullable = true)\n",
      " |    |-- genres: string (nullable = true)\n",
      " |-- _2: struct (nullable = false)\n",
      " |    |-- movieId: integer (nullable = true)\n",
      " |    |-- avg(rating): double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movieRatingsDS.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9378a438-564a-4ef4-8226-27918bd3d9d0",
   "metadata": {},
   "source": [
    "> üíÅüèª‚Äç‚ôÇÔ∏è Important to notice that the return type of the `joinWith` operation is `Dataset`.\n",
    "\n",
    "Safe access to the top 10 rated films:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b26dc112-a6d9-4805-a172-b2f6926d6e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------+\n",
      "|value                                                       |\n",
      "+------------------------------------------------------------+\n",
      "|avg ratings for the Awfully Big Adventure, An (1995) is 5.0 |\n",
      "|avg ratings for the What Happened Was... (1994) is 5.0      |\n",
      "|avg ratings for the Strictly Sexual (2008) is 5.0           |\n",
      "|avg ratings for the The Love Bug (1997) is 5.0              |\n",
      "|avg ratings for the The Editor (2015) is 5.0                |\n",
      "|avg ratings for the Tenchi Muy√¥! In Love (1996) is 5.0      |\n",
      "|avg ratings for the Raise Your Voice (2004) is 5.0          |\n",
      "|avg ratings for the One I Love, The (2014) is 5.0           |\n",
      "|avg ratings for the Empties (2007) is 5.0                   |\n",
      "|avg ratings for the Who Killed Chea Vichea? (2010) is 5.0   |\n",
      "+------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movieRatingsDS.map{ case (m, r) => \n",
    "    s\"avg ratings for the ${m.title} is ${r.getAs[Double](\"avg(rating)\")} \" }.show(10, truncate=false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295b5ad4-202b-4edd-b0c1-e05d49735359",
   "metadata": {},
   "source": [
    "Let's join the above `movieRatingsDS` with Tags data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8102c8c7-0fa6-40c3-8fa6-bac495697038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mclass\u001b[39m \u001b[36mTag\u001b[39m"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case class Tag(\n",
    "  userId: Int,\n",
    "  movieId: Int,\n",
    "  tag: String,\n",
    "  timestamp: Long\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fd066bc5-a52f-4481-b77c-9ebbcdda7abd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mtagsDS\u001b[39m: \u001b[32mDataset\u001b[39m[\u001b[32mTag\u001b[39m] = [userId: int, movieId: int ... 2 more fields]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val tagsDS = spark.read\n",
    "  .option(\"header\", \"true\")\n",
    "  .option(\"inferSchema\", \"true\")\n",
    "  .csv(\"ml-latest-small/tags.csv\")\n",
    "  .as[Tag]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8191e6d2-2cfe-4f0b-9b54-2aeb7cde173e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+---------------+----------+\n",
      "|userId|movieId|tag            |timestamp |\n",
      "+------+-------+---------------+----------+\n",
      "|2     |60756  |funny          |1445714994|\n",
      "|2     |60756  |Highly quotable|1445714996|\n",
      "|2     |60756  |will ferrell   |1445714992|\n",
      "+------+-------+---------------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tagsDS.show(3, truncate=false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b60689-1049-4c94-a764-884354025d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "It is better to create an extensible key and join condition first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b11ce43e-30b1-48e1-830c-d4e7d301c4cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mkeyCols\u001b[39m: \u001b[32mSeq\u001b[39m[\u001b[32mString\u001b[39m] = \u001b[33mList\u001b[39m(\u001b[32m\"movieId\"\u001b[39m, \u001b[32m\"userId\"\u001b[39m)\n",
       "\u001b[36mkeyCondition\u001b[39m: \u001b[32mColumn\u001b[39m = ((movieId = movieId) AND (userId = userId))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val keyCols = Seq(\"movieId\", \"userId\")\n",
    "val keyCondition = keyCols.map(col => tagsDS(col) === ratingsDS(col)).reduce( _ && _ ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48e192e-8159-44b0-b653-9faa91212d0a",
   "metadata": {},
   "source": [
    "First, join the `ratingsDS` and the `tagsDS`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "22baddcb-fc2d-4365-8f5f-8a946a63586b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mtags4RatingsDS\u001b[39m: \u001b[32mDataset\u001b[39m[(\u001b[32mRating\u001b[39m, \u001b[32mTag\u001b[39m)] = [_1: struct<userId: int, movieId: int ... 2 more fields>, _2: struct<userId: int, movieId: int ... 2 more fields>]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val tags4RatingsDS = ratingsDS.joinWith(tagsDS, keyCondition, \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d5de516e-3fa5-4ddb-b1fc-1e048b6ebe96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _1: struct (nullable = false)\n",
      " |    |-- userId: integer (nullable = true)\n",
      " |    |-- movieId: integer (nullable = true)\n",
      " |    |-- rating: double (nullable = true)\n",
      " |    |-- timestamp: integer (nullable = true)\n",
      " |-- _2: struct (nullable = true)\n",
      " |    |-- userId: integer (nullable = true)\n",
      " |    |-- movieId: integer (nullable = true)\n",
      " |    |-- tag: string (nullable = true)\n",
      " |    |-- timestamp: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tags4RatingsDS.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "93203d1a-8e0d-4792-a99f-7f67c1adc80f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+\n",
      "|                  _1|  _2|\n",
      "+--------------------+----+\n",
      "|{1, 1, 4.0, 96498...|null|\n",
      "|{1, 3, 4.0, 96498...|null|\n",
      "|{1, 6, 4.0, 96498...|null|\n",
      "+--------------------+----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tags4RatingsDS.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f6da02-1a8b-464b-9f26-8e4fce3d5c35",
   "metadata": {},
   "source": [
    "Secondly join the `moviesDS` where `movieId` is a FK for the `tags4RatingsDS`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e451c165-a339-4f54-937c-eb786b40fbdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mtags4RatingsWithMoviesDS\u001b[39m: \u001b[32mDataset\u001b[39m[((\u001b[32mRating\u001b[39m, \u001b[32mTag\u001b[39m), \u001b[32mMovie\u001b[39m)] = [_1: struct<_1: struct<userId: int, movieId: int ... 2 more fields>, _2: struct<userId: int, movieId: int ... 2 more fields>>, _2: struct<movieId: int, title: string ... 1 more field>]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val tags4RatingsWithMoviesDS = tags4RatingsDS.joinWith(moviesDS, \n",
    "                        tags4RatingsDS(\"_1.movieId\") === moviesDS(\"movieId\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c555c143-5a37-4381-815d-9f51d7688b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _1: struct (nullable = false)\n",
      " |    |-- _1: struct (nullable = false)\n",
      " |    |    |-- userId: integer (nullable = true)\n",
      " |    |    |-- movieId: integer (nullable = true)\n",
      " |    |    |-- rating: double (nullable = true)\n",
      " |    |    |-- timestamp: integer (nullable = true)\n",
      " |    |-- _2: struct (nullable = true)\n",
      " |    |    |-- userId: integer (nullable = true)\n",
      " |    |    |-- movieId: integer (nullable = true)\n",
      " |    |    |-- tag: string (nullable = true)\n",
      " |    |    |-- timestamp: integer (nullable = true)\n",
      " |-- _2: struct (nullable = false)\n",
      " |    |-- movieId: integer (nullable = true)\n",
      " |    |-- title: string (nullable = true)\n",
      " |    |-- genres: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tags4RatingsWithMoviesDS.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a8b75b-6c86-47fb-af6b-ffad276e934d",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "---\n",
    "config:\n",
    "  look: neo\n",
    "  theme: default\n",
    "---\n",
    "graph LR\n",
    "    root[root]\n",
    "    root --> _1_outer[\"_1: struct\"]\n",
    "    root --> _2_outer[\"_2: struct\"]\n",
    "    \n",
    "    _1_outer --> _1_inner[\"_1: struct\"]\n",
    "    _1_outer --> _2_inner[\"_2: struct\"]\n",
    "    \n",
    "    _1_inner --> userId1[\"userId: integer\"]\n",
    "    _1_inner --> movieId1[\"movieId: integer\"]\n",
    "    _1_inner --> rating[\"rating: double\"]\n",
    "    _1_inner --> timestamp1[\"timestamp: integer\"]\n",
    "    \n",
    "    _2_inner --> userId2[\"userId: integer\"]\n",
    "    _2_inner --> movieId2[\"movieId: integer\"]\n",
    "    _2_inner --> tag[\"tag: string\"]\n",
    "    _2_inner --> timestamp2[\"timestamp: integer\"]\n",
    "    \n",
    "    _2_outer --> movieId3[\"movieId: integer\"]\n",
    "    _2_outer --> title[\"title: string\"]\n",
    "    _2_outer --> genres[\"genres: string\"]\n",
    "    \n",
    "    style root fill:#e1f5ff\n",
    "    style _1_outer fill:#fff4e6\n",
    "    style _2_outer fill:#fff4e6\n",
    "    style _1_inner fill:#f0f0f0\n",
    "    style _2_inner fill:#f0f0f0\n",
    "```\n",
    "\n",
    "Pattern matching extracts all nested elements. To access the `tags4RatingsWithMoviesDS`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "0feb31f4-cdd4-4870-932a-2bfd3f482f9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mclass\u001b[39m \u001b[36mUserRatingTag\u001b[39m\n",
       "\u001b[36muserRatingTagDS\u001b[39m: \u001b[32mDataset\u001b[39m[\u001b[32mUserRatingTag\u001b[39m] = [userId: int, movie: string ... 2 more fields]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case class UserRatingTag(userId: Int, \n",
    "                         movie: String, \n",
    "                         rating: Double, \n",
    "                         tag: Option[String] \n",
    "                        )\n",
    "\n",
    "val userRatingTagDS = tags4RatingsWithMoviesDS.map {\n",
    "\n",
    "    case ((r, t), m) => UserRatingTag(\n",
    "        r.userId,\n",
    "        m.title,\n",
    "        r.rating,\n",
    "        Option(t).map(_.tag)\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c01b9174-11da-4c84-b556-9c57964ddc36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------------------+------+-----------------+\n",
      "|userId|movie                          |rating|tag              |\n",
      "+------+-------------------------------+------+-----------------+\n",
      "|2     |Step Brothers (2008)           |5.0   |will ferrell     |\n",
      "|2     |Step Brothers (2008)           |5.0   |Highly quotable  |\n",
      "|2     |Step Brothers (2008)           |5.0   |funny            |\n",
      "|2     |Warrior (2011)                 |5.0   |Tom Hardy        |\n",
      "|2     |Warrior (2011)                 |5.0   |MMA              |\n",
      "|2     |Warrior (2011)                 |5.0   |Boxing story     |\n",
      "|2     |Wolf of Wall Street, The (2013)|5.0   |Martin Scorsese  |\n",
      "|2     |Wolf of Wall Street, The (2013)|5.0   |Leonardo DiCaprio|\n",
      "|2     |Wolf of Wall Street, The (2013)|5.0   |drugs            |\n",
      "|7     |Departed, The (2006)           |1.0   |way too long     |\n",
      "|18    |Carlito's Way (1993)           |4.0   |mafia            |\n",
      "|18    |Carlito's Way (1993)           |4.0   |gangster         |\n",
      "|18    |Carlito's Way (1993)           |4.0   |Al Pacino        |\n",
      "|18    |Godfather: Part II, The (1974) |5.0   |Mafia            |\n",
      "|18    |Godfather: Part II, The (1974) |5.0   |Al Pacino        |\n",
      "|18    |Pianist, The (2002)            |4.5   |true story       |\n",
      "|18    |Pianist, The (2002)            |4.5   |holocaust        |\n",
      "|18    |Lucky Number Slevin (2006)     |4.5   |twist ending     |\n",
      "|18    |Fracture (2007)                |4.5   |twist ending     |\n",
      "|18    |Fracture (2007)                |4.5   |courtroom drama  |\n",
      "+------+-------------------------------+------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "userRatingTagDS.filter(u => u.tag != None).show(truncate=false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15640cc-d3f6-4b5b-86b2-5d3588c565eb",
   "metadata": {},
   "source": [
    "[^1]: Chambers, B., Zaharia, M., 2018. Spark: The Definitive Guide. Ch. 11: \"Datasets\"\n",
    "\n",
    "[^2]: Holden Karau, Rachel Warren., 2017. High Performance Spark: Best Practices for Scaling and Optimizing Apache Spark. Ch. 3: \"DataFrames, Datasets, and Spark SQL\"\n",
    "\n",
    "[^3]: Chambers, B., Zaharia, M., 2018. Spark: The Definitive Guide. Ch. 13: \"Advanced RDDs\"\n",
    "\n",
    "[^4]: Holden Karau, Rachel Warren., 2017. High Performance Spark: Best Practices for Scaling and Optimizing Apache Spark. Ch. 4: \"Joins (SQL and Core)\"\n",
    "\n",
    "[^5]: Holden Karau, Rachel Warren., 2017. High Performance Spark: Best Practices for Scaling and Optimizing Apache Spark. Ch. 6: \"Working with Key/Value Data\"\n",
    "\n",
    "[^6]: Ryza, Sandy, Laserson, Uri, Owen, Sean, Wills, Josh., 2017. Advanced Analytics with Spark, 2nd Edition. Ch. 2: \"Introduction to Data Analysis with Scala and Spark\"\n",
    "\n",
    "[^7]: [Apache Spark Dataset API Documentation](https://spark.apache.org/docs/2.4.8/api/scala/index.html#org.apache.spark.sql.Dataset) - Scala 2.x API\n",
    "\n",
    "{:gtxt: .message color=\"green\"}\n",
    "{:ytxt: .message color=\"yellow\"}\n",
    "{:rtxt: .message color=\"red\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908b9b1b-b10b-470f-b441-820d95eec157",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0664f90-f90f-43c2-ae13-0ce976ab2bfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mres21\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"version 2.12.20\"\u001b[39m"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scala.util.Properties.versionString\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c2f6c6ce-35ca-43c2-b34c-fb17fa54ec83",
   "metadata": {},
   "outputs": [],
   "source": [
    "// spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a364aa93-80a7-4f5f-942f-aa2f4039a190",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala 2.12",
   "language": "scala",
   "name": "scala212"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
